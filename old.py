import base64
import hashlib
import json
import time
import threading
from typing import Any, Dict, List, Optional, Set, Tuple
from dataclasses import dataclass, field
from queue import Queue
import numpy as np
from cryptography.exceptions import InvalidSignature
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from cryptography.hazmat.primitives import hashes, serialization
from cryptography.hazmat.primitives.asymmetric import ed25519, x25519
from cryptography.hazmat.primitives.kdf.hkdf import HKDF
from cryptography.hazmat.backends import default_backend
import os

from secure_rng import SecureRandom

# ä½¿ç”¨å¤§ç´ æ•°ä»¥ä¿è¯Shamirç§˜å¯†å…±äº«çš„å®‰å…¨æ€§
PRIME = 2**255 - 19

@dataclass
class Share:
    value: int
    index: int

@dataclass
class PerformanceStats:
    """æ€§èƒ½ç»Ÿè®¡æ•°æ®ç±»"""
    phase_name: str
    duration: float  # ç§’
    operations: Dict[str, int] = None
    
    def __post_init__(self):
        if self.operations is None:
            self.operations = {}

@dataclass
class EncryptedSharePackage:
    """åŠ å¯†çš„ä»½é¢åŒ…"""
    sender_id: int
    receiver_id: int
    encrypted_data: bytes
    nonce: bytes
    kem_public: bytes
    key_signature: bytes
    signature: bytes

@dataclass
class PublicProof:
    """å…¬å¼€è¯æ˜"""
    participant_id: int
    merkle_root: str
    salt: str
    participant_salt: str  # å‚ä¸è€…çš„éšæœºç›å€¼ salt_i
    v_shares: List[List[int]]
    aggregated_v: List[int]
    R: List[List[int]]
    bound: float
    spectral_norm: float

@dataclass
class AggregatedShare:
    """èšåˆä»½é¢æ¶ˆæ¯"""
    participant_id: int      # å‘é€è€…ID
    aggregated_values: List[int]  # èšåˆåçš„dç»´ä»½é¢å€¼ï¼ˆåœ¨è¯¥å‚ä¸è€…ä½ç½®ï¼‰

@dataclass
class Complaint:
    """æŠ•è¯‰æ¶ˆæ¯"""
    complainer_id: int      # æŠ•è¯‰è€…ID
    accused_id: int         # è¢«æŠ•è¯‰è€…ID
    reason: str             # æŠ•è¯‰åŸå› 
    timestamp: float        # æŠ•è¯‰æ—¶é—´æˆ³
    evidence_package: Optional[EncryptedSharePackage] = None
    symmetric_key: Optional[bytes] = None
    complainer_signature: Optional[bytes] = None
    sender_key_signature: Optional[bytes] = None


@dataclass
class ValidationVector:
    """éªŒè¯ç»“æœå¹¿æ’­"""

    participant_id: int
    accepted_ids: List[int]

class MerkleNode:
    def __init__(self, hash_value: str, left=None, right=None):
        self.hash = hash_value
        self.left = left
        self.right = right

class MerkleTree:
    def __init__(self, leaves: List[str]):
        if len(leaves) % 2 == 1:
            leaves = leaves + [leaves[-1]]
        self.leaves = leaves
        self.root = self.build_tree([MerkleNode(h) for h in leaves])

    @staticmethod
    def hash_item(item: str) -> str:
        return hashlib.sha256(item.encode()).hexdigest()

    def build_tree(self, nodes: List[MerkleNode]):
        if not nodes:
            return MerkleNode('')
        while len(nodes) > 1:
            if len(nodes) % 2 == 1:
                nodes = nodes + [nodes[-1]]
            new_level = []
            for i in range(0, len(nodes), 2):
                left = nodes[i]
                right = nodes[i+1]
                parent_hash = self.hash_item(left.hash + right.hash)
                new_level.append(MerkleNode(parent_hash, left, right))
            nodes = new_level
        return nodes[0]

    def get_proof(self, index: int) -> List[Tuple[str, str]]:
        proof = []
        idx = index
        level = [MerkleNode(h) for h in self.leaves]
        while len(level) > 1:
            if len(level) % 2 == 1:
                level = level + [level[-1]]
            new_level = []
            for i in range(0, len(level), 2):
                left = level[i]
                right = level[i+1]
                parent_hash = self.hash_item(left.hash + right.hash)
                new_level.append(MerkleNode(parent_hash, left, right))
            sibling_idx = idx ^ 1
            if sibling_idx < len(level) and sibling_idx != idx:
                position = 'left' if idx % 2 else 'right'
                proof.append((level[sibling_idx].hash, position))
            idx //= 2
            level = new_level
        return proof

    @staticmethod
    def verify_proof(leaf_hash: str, proof: List[Tuple[str, str]], root_hash: str) -> bool:
        computed_hash = leaf_hash
        for sibling_hash, position in proof:
            if position == 'left':
                computed_hash = MerkleTree.hash_item(sibling_hash + computed_hash)
            else:
                computed_hash = MerkleTree.hash_item(computed_hash + sibling_hash)
        return computed_hash == root_hash

class CryptoManager:
    """åŠ å¯†ç®¡ç†å™¨ï¼Œå¤„ç†å¯†é’¥æ´¾ç”Ÿã€KEMå°è£…ä»¥åŠç­¾åæ ¡éªŒ."""

    KEM_INFO = b"v3s-kem-share"

    @staticmethod
    def encrypt_data(data: dict, key: bytes) -> Tuple[bytes, bytes]:
        """ä½¿ç”¨AES-GCMåŠ å¯†æ•°æ® / Encrypt serialized data with AES-GCM."""
        aesgcm = AESGCM(key)
        nonce = os.urandom(12)
        serialized_data = json.dumps(data).encode()
        ciphertext = aesgcm.encrypt(nonce, serialized_data, None)
        return ciphertext, nonce

    @staticmethod
    def decrypt_data(ciphertext: bytes, nonce: bytes, key: bytes) -> dict:
        """ä½¿ç”¨AES-GCMè§£å¯†æ•°æ® / Decrypt ciphertext produced by AES-GCM."""
        aesgcm = AESGCM(key)
        plaintext = aesgcm.decrypt(nonce, ciphertext, None)
        return json.loads(plaintext.decode())

    # â€”â€” KEM ä¸ç­¾åç›¸å…³å·¥å…· â€”â€”

    @staticmethod
    def generate_signature_keypair() -> Tuple[ed25519.Ed25519PrivateKey, bytes]:
        """ç”ŸæˆEd25519ç­¾åå¯†é’¥å¯¹ / Generate an Ed25519 signing key pair."""
        private_key = ed25519.Ed25519PrivateKey.generate()
        public_key = private_key.public_key().public_bytes(
            encoding=serialization.Encoding.Raw,
            format=serialization.PublicFormat.Raw,
        )
        return private_key, public_key

    @staticmethod
    def generate_kem_keypair() -> Tuple[x25519.X25519PrivateKey, bytes]:
        """ç”ŸæˆX25519å¯†é’¥å¯¹ç”¨äºKEMå°è£… / Generate an X25519 key pair for KEM encapsulation."""
        private_key = x25519.X25519PrivateKey.generate()
        public_key = private_key.public_key().public_bytes(
            encoding=serialization.Encoding.Raw,
            format=serialization.PublicFormat.Raw,
        )
        return private_key, public_key

    @staticmethod
    def encapsulate_key(receiver_public_bytes: bytes, context: bytes) -> Tuple[bytes, bytes]:
        """ä½¿ç”¨æ¥æ”¶è€…å…¬é’¥å°è£…å¯¹ç§°å¯†é’¥ï¼Œè¿”å›(å¯¹ç§°å¯†é’¥, å‘é€æ–¹ä¸´æ—¶å…¬é’¥)."""
        receiver_public = x25519.X25519PublicKey.from_public_bytes(receiver_public_bytes)
        ephemeral_private = x25519.X25519PrivateKey.generate()
        shared_secret = ephemeral_private.exchange(receiver_public)
        symmetric_key = CryptoManager._derive_symmetric_key(shared_secret, context)
        ephemeral_public_bytes = ephemeral_private.public_key().public_bytes(
            encoding=serialization.Encoding.Raw,
            format=serialization.PublicFormat.Raw,
        )
        return symmetric_key, ephemeral_public_bytes

    @staticmethod
    def decapsulate_key(ephemeral_public_bytes: bytes, receiver_private: x25519.X25519PrivateKey, context: bytes) -> bytes:
        """è§£å°è£…å¯¹ç§°å¯†é’¥ / Decapsulate the symmetric key using receiver's private key."""
        ephemeral_public = x25519.X25519PublicKey.from_public_bytes(ephemeral_public_bytes)
        shared_secret = receiver_private.exchange(ephemeral_public)
        return CryptoManager._derive_symmetric_key(shared_secret, context)

    @staticmethod
    def sign_message(message: bytes, signing_private: ed25519.Ed25519PrivateKey) -> bytes:
        """å¯¹æ¶ˆæ¯è¿›è¡Œç­¾å / Sign a message with Ed25519."""
        return signing_private.sign(message)

    @staticmethod
    def verify_signature(signature: bytes, message: bytes, signing_public_bytes: bytes) -> bool:
        """éªŒè¯Ed25519ç­¾åï¼Œè¿”å›æ˜¯å¦æœ‰æ•ˆ."""
        try:
            public_key = ed25519.Ed25519PublicKey.from_public_bytes(signing_public_bytes)
            public_key.verify(signature, message)
            return True
        except InvalidSignature:
            return False

    @staticmethod
    def serialize_share_package(package: EncryptedSharePackage, include_signature: bool = False) -> bytes:
        """åºåˆ—åŒ–åŠ å¯†ä»½é¢åŒ…ç”¨äºç­¾å / Serialize package deterministically for signing."""
        payload = {
            'sender_id': package.sender_id,
            'receiver_id': package.receiver_id,
            'nonce': base64.b64encode(package.nonce).decode(),
            'encrypted_data': base64.b64encode(package.encrypted_data).decode(),
            'kem_public': base64.b64encode(package.kem_public).decode(),
            'key_signature': base64.b64encode(package.key_signature).decode(),
        }

        if include_signature and package.signature:
            payload['signature'] = base64.b64encode(package.signature).decode()

        return json.dumps(payload, sort_keys=True).encode()

    @staticmethod
    def serialize_complaint_evidence(package: EncryptedSharePackage, symmetric_key: bytes) -> bytes:
        """åºåˆ—åŒ–æŠ•è¯‰è¯æ®ä¾›æŠ•è¯‰è€…ç­¾å / Serialize complaint evidence for signing."""
        payload = {
            'sender_id': package.sender_id,
            'receiver_id': package.receiver_id,
            'nonce': base64.b64encode(package.nonce).decode(),
            'encrypted_data': base64.b64encode(package.encrypted_data).decode(),
            'kem_public': base64.b64encode(package.kem_public).decode(),
            'symmetric_key': base64.b64encode(symmetric_key).decode(),
            'sender_key_signature': base64.b64encode(package.key_signature).decode(),
        }
        return json.dumps(payload, sort_keys=True).encode()

    @staticmethod
    def serialize_key_binding(sender_id: int, receiver_id: int, symmetric_key: bytes) -> bytes:
        """åºåˆ—åŒ–å‘é€è€…å¯¹å¯¹ç§°å¯†é’¥çš„ç»‘å®šä¿¡æ¯ / Serialize key binding for signing and verification."""
        payload = {
            'receiver_id': receiver_id,
            'sender_id': sender_id,
            'symmetric_key': base64.b64encode(symmetric_key).decode(),
        }
        return json.dumps(payload, sort_keys=True).encode()

    @staticmethod
    def _derive_symmetric_key(shared_secret: bytes, context: bytes) -> bytes:
        """é€šè¿‡HKDFä»å…±äº«ç§˜å¯†å¯¼å‡ºå¯¹ç§°å¯†é’¥."""
        hkdf = HKDF(
            algorithm=hashes.SHA256(),
            length=32,
            salt=None,
            info=context or CryptoManager.KEM_INFO,
            backend=default_backend(),
        )
        return hkdf.derive(shared_secret)

class NetworkSimulator:
    """ç½‘ç»œæ¨¡æ‹Ÿå™¨ï¼Œç”¨äºå‚ä¸è€…ä¹‹é—´çš„é€šä¿¡"""
    
    def __init__(self):
        self.message_queues: Dict[int, Queue] = {}
        self.broadcast_queue: Queue = Queue()
        self.lock = threading.Lock()
        self.signing_public_keys: Dict[int, bytes] = {}
        self.kem_public_keys: Dict[int, bytes] = {}
    
    def register_participant(
        self,
        participant_id: int,
        signing_public_key: Optional[bytes] = None,
        kem_public_key: Optional[bytes] = None,
    ) -> None:
        """æ³¨å†Œå‚ä¸è€…å¹¶è®°å½•å…¶å…¬é’¥"""
        with self.lock:
            if participant_id not in self.message_queues:
                self.message_queues[participant_id] = Queue()
            if signing_public_key is not None and kem_public_key is not None:
                self.signing_public_keys[participant_id] = signing_public_key
                self.kem_public_keys[participant_id] = kem_public_key

    def get_signing_public_key(self, participant_id: int) -> bytes:
        with self.lock:
            return self.signing_public_keys[participant_id]

    def get_kem_public_key(self, participant_id: int) -> bytes:
        with self.lock:
            return self.kem_public_keys[participant_id]
    
    def send_encrypted_share(self, package: EncryptedSharePackage):
        """å‘é€åŠ å¯†ä»½é¢"""
        with self.lock:
            if package.receiver_id in self.message_queues:
                self.message_queues[package.receiver_id].put(('share', package))
    
    def broadcast_proof(self, proof: PublicProof):
        """å¹¿æ’­å…¬å¼€è¯æ˜"""
        with self.lock:
            for participant_id in self.message_queues.keys():
                self.message_queues[participant_id].put(('proof', proof))
    
    def broadcast_complaint(self, complaint: Complaint):
        """å¹¿æ’­æŠ•è¯‰æ¶ˆæ¯"""
        with self.lock:
            for participant_id in self.message_queues.keys():
                self.message_queues[participant_id].put(('complaint', complaint))
    
    def broadcast_aggregated_share(self, agg_share: 'AggregatedShare'):
        """å¹¿æ’­èšåˆä»½é¢"""
        with self.lock:
            for participant_id in self.message_queues.keys():
                self.message_queues[participant_id].put(('aggregated', agg_share))

    def broadcast_validation_vector(self, validation: ValidationVector) -> None:
        """å¹¿æ’­æœ¬åœ°éªŒè¯ç»“æœ"""
        with self.lock:
            for participant_id in self.message_queues.keys():
                self.message_queues[participant_id].put(('validation', validation))
    
    def receive_encrypted_shares(self, participant_id: int, timeout: float = 5.0) -> List[EncryptedSharePackage]:
        """æ¥æ”¶åŠ å¯†ä»½é¢"""
        shares = []
        messages_to_requeue = []
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                msg_type, data = self.message_queues[participant_id].get(timeout=0.1)
                if msg_type == 'share':
                    shares.append(data)
                else:
                    # å¦‚æœæ˜¯proofæ¶ˆæ¯ï¼Œé‡æ–°æ”¾å›é˜Ÿåˆ—
                    messages_to_requeue.append((msg_type, data))
            except:
                break
        
        # å°†éshareæ¶ˆæ¯é‡æ–°æ”¾å›é˜Ÿåˆ—
        for msg in messages_to_requeue:
            self.message_queues[participant_id].put(msg)
        
        return shares
    
    def receive_all_proofs(self, participant_id: int, expected_count: int, timeout: float = 5.0) -> List[PublicProof]:
        """æ¥æ”¶æ‰€æœ‰å…¬å¼€è¯æ˜"""
        proofs = []
        messages_to_requeue = []
        start_time = time.time()
        
        while len(proofs) < expected_count and time.time() - start_time < timeout:
            try:
                msg_type, data = self.message_queues[participant_id].get(timeout=0.1)
                if msg_type == 'proof':
                    proofs.append(data)
                else:
                    # å¦‚æœæ˜¯shareæˆ–complaintæ¶ˆæ¯ï¼Œé‡æ–°æ”¾å›é˜Ÿåˆ—
                    messages_to_requeue.append((msg_type, data))
            except:
                break
        
        # å°†éproofæ¶ˆæ¯é‡æ–°æ”¾å›é˜Ÿåˆ—
        for msg in messages_to_requeue:
            self.message_queues[participant_id].put(msg)
        
        return proofs
    
    def receive_complaints(self, participant_id: int, timeout: float = 2.0) -> List[Complaint]:
        """æ¥æ”¶æŠ•è¯‰æ¶ˆæ¯"""
        complaints = []
        messages_to_requeue = []
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                msg_type, data = self.message_queues[participant_id].get(timeout=0.1)
                if msg_type == 'complaint':
                    complaints.append(data)
                else:
                    # å¦‚æœæ˜¯å…¶ä»–ç±»å‹æ¶ˆæ¯ï¼Œé‡æ–°æ”¾å›é˜Ÿåˆ—
                    messages_to_requeue.append((msg_type, data))
            except:
                break
        
        # å°†écomplaintæ¶ˆæ¯é‡æ–°æ”¾å›é˜Ÿåˆ—
        for msg in messages_to_requeue:
            self.message_queues[participant_id].put(msg)
        
        return complaints
    
    def receive_aggregated_shares(self, participant_id: int, expected_count: int, timeout: float = 3.0) -> List['AggregatedShare']:
        """æ¥æ”¶èšåˆä»½é¢"""
        agg_shares = []
        messages_to_requeue = []
        start_time = time.time()
        
        while len(agg_shares) < expected_count and time.time() - start_time < timeout:
            try:
                msg_type, data = self.message_queues[participant_id].get(timeout=0.1)
                if msg_type == 'aggregated':
                    agg_shares.append(data)
                else:
                    # å¦‚æœæ˜¯å…¶ä»–ç±»å‹æ¶ˆæ¯ï¼Œé‡æ–°æ”¾å›é˜Ÿåˆ—
                    messages_to_requeue.append((msg_type, data))
            except:
                break
        
        # å°†éaggregatedæ¶ˆæ¯é‡æ–°æ”¾å›é˜Ÿåˆ—
        for msg in messages_to_requeue:
            self.message_queues[participant_id].put(msg)
        
        return agg_shares

    def receive_validation_vectors(
        self,
        participant_id: int,
        expected_count: int,
        timeout: float = 3.0,
    ) -> List[ValidationVector]:
        """æ¥æ”¶éªŒè¯ç»“æœå¹¿æ’­"""
        vectors: List[ValidationVector] = []
        messages_to_requeue = []
        start_time = time.time()

        while len(vectors) < expected_count and time.time() - start_time < timeout:
            try:
                msg_type, data = self.message_queues[participant_id].get(timeout=0.1)
                if msg_type == 'validation':
                    vectors.append(data)
                else:
                    messages_to_requeue.append((msg_type, data))
            except:
                break

        for msg in messages_to_requeue:
            self.message_queues[participant_id].put(msg)

        return vectors

class V3S:
    def __init__(self, n: int, t: int, prime: int = PRIME, slack_factor: float = 10.0, rng: Optional[SecureRandom] = None):
        self.n = n
        self.t = t
        self.prime = prime
        self.slack_factor = slack_factor
        self.performance_stats = []
        self.rng = rng or SecureRandom("legacy-v3s-core")
    
    def add_performance_stat(self, phase_name: str, duration: float, operations: Dict[str, int] = None):
        stat = PerformanceStats(phase_name, duration, operations or {})
        self.performance_stats.append(stat)
    
    def print_performance_report(self):
        """æ‰“å°ä¼˜é›…çš„æ€§èƒ½æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("***  PROTOCOL PERFORMANCE ANALYSIS REPORT  ***".center(80))
        print("="*80 + "\n")
        
        total_time = sum(stat.duration for stat in self.performance_stats)
        
        # æ‰“å°æ¯ä¸ªé˜¶æ®µçš„ç»Ÿè®¡
        for idx, stat in enumerate(self.performance_stats, 1):
            percentage = (stat.duration / total_time * 100) if total_time > 0 else 0
            
            print(f"â”Œâ”€ Phase {idx}: {stat.phase_name}")
            print(f"â”‚  â±  Duration:    {stat.duration*1000:.4f} ms  ({percentage:.1f}% of total)")
            
            if stat.operations:
                print(f"â”‚  ğŸ“Š æ“ä½œæ¬¡æ•°:")
                for op_name, count in stat.operations.items():
                    print(f"â”‚     â€¢ {op_name}: {count:,}")
            print(f"â””{'â”€'*78}\n")
        
        # æ‰“å°æ€»è®¡
        print("="*80)
        print(f"ğŸ• TOTAL EXECUTION TIME: {total_time*1000:.4f} ms ({total_time:.6f} seconds)")
        print("="*80 + "\n")
    
    def compute_spectral_norm(self, matrix: np.ndarray) -> float:
        singular_values = np.linalg.svd(matrix, compute_uv=False)
        return float(singular_values[0])
    
    def compute_bound(self, R: np.ndarray, sigma_x: float, sigma_y: float, d: int) -> float:
        spectral_norm = self.compute_spectral_norm(R)
        sigma_p = spectral_norm * sigma_x
        sigma_v = sigma_p + sigma_y
        bound = self.slack_factor * sigma_v * np.sqrt(2 * d)
        return bound
    
    def lagrange_interpolate(self, shares: List[Share]) -> int:
        secret = 0
        k = len(shares)
        
        for i in range(k):
            xi = shares[i].index
            yi = shares[i].value
            
            numerator = 1
            denominator = 1
            
            for j in range(k):
                if i != j:
                    xj = shares[j].index
                    numerator = (numerator * (0 - xj)) % self.prime
                    denominator = (denominator * (xi - xj)) % self.prime
            
            denominator_inv = pow(denominator, self.prime - 2, self.prime)
            secret = (secret + yi * numerator * denominator_inv) % self.prime
        
        return int(secret)

    @staticmethod
    def _solve_linear_system_mod(matrix: List[List[int]], vector: List[int], prime: int) -> List[int]:
        """åœ¨æœ‰é™åŸŸGF(prime)ä¸Šæ±‚è§£çº¿æ€§æ–¹ç¨‹ç»„"""
        if not matrix:
            raise ValueError("Empty linear system")

        rows = len(matrix)
        cols = len(matrix[0])
        aug = [row[:] + [vector[i] % prime] for i, row in enumerate(matrix)]
        rank = 0

        for col in range(cols):
            pivot_row = None
            for r in range(rank, rows):
                if aug[r][col] % prime != 0:
                    pivot_row = r
                    break
            if pivot_row is None:
                continue

            aug[rank], aug[pivot_row] = aug[pivot_row], aug[rank]
            pivot_inv = pow(aug[rank][col] % prime, prime - 2, prime)
            for c in range(col, cols + 1):
                aug[rank][c] = (aug[rank][c] * pivot_inv) % prime

            for r in range(rows):
                if r != rank and aug[r][col] % prime != 0:
                    factor = aug[r][col] % prime
                    for c in range(col, cols + 1):
                        aug[r][c] = (aug[r][c] - factor * aug[rank][c]) % prime

            rank += 1
            if rank == cols:
                break

        solution = [0] * cols

        for row in range(rank - 1, -1, -1):
            lead_col = None
            for col in range(cols):
                if aug[row][col] % prime != 0:
                    lead_col = col
                    break
            if lead_col is None:
                if aug[row][-1] % prime != 0:
                    raise ValueError("Inconsistent linear system")
                continue

            rhs = aug[row][-1]
            for col in range(lead_col + 1, cols):
                rhs = (rhs - aug[row][col] * solution[col]) % prime
            solution[lead_col] = rhs % prime

        for r in range(rows):
            lhs = 0
            for c in range(cols):
                lhs = (lhs + (matrix[r][c] % prime) * solution[c]) % prime
            if lhs != vector[r] % prime:
                raise ValueError("Linear system has no solution")

        return solution

    def reed_solomon_reconstruct(self, shares: List[Share]) -> int:
        """ä½¿ç”¨Reedâ€“Solomonçº é”™é‡æ„ç§˜å¯†"""
        num_shares = len(shares)
        if num_shares < self.t:
            raise ValueError("Insufficient shares for reconstruction")

        max_correctable = max(0, (num_shares - self.t) // 2)
        if max_correctable == 0:
            return self.lagrange_interpolate(shares[:self.t])

        unknowns = self.t + max_correctable
        if num_shares < unknowns:
            return self.lagrange_interpolate(shares[:self.t])

        matrix: List[List[int]] = []
        vector: List[int] = []

        for share in shares:
            x_val = share.index % self.prime
            y_val = share.value % self.prime

            row: List[int] = []
            x_power = 1
            for _ in range(self.t):
                row.append(x_power)
                x_power = (x_power * x_val) % self.prime

            for error_deg in range(1, max_correctable + 1):
                term = (-y_val * pow(x_val, error_deg, self.prime)) % self.prime
                row.append(term)

            matrix.append(row)
            vector.append(y_val)

        try:
            solution = self._solve_linear_system_mod(matrix, vector, self.prime)
        except ValueError:
            return self.lagrange_interpolate(shares[:self.t])

        secret = solution[0] % self.prime
        return int(secret)

    def generate_random_matrix(self, d: int, n: int, seed: str) -> np.ndarray:
        random_bytes = hashlib.shake_128(seed.encode()).digest(n * d // 4 + 1)
        matrix = np.zeros((d, n), dtype=int)
        byte_idx = 0
        bit_pair_idx = 0
        current_byte = random_bytes[0]
        for i in range(d):
            for j in range(n):
                if bit_pair_idx == 4:
                    byte_idx += 1
                    current_byte = random_bytes[byte_idx]
                    bit_pair_idx = 0
                bit_pair = (current_byte >> (2 * bit_pair_idx)) & 0b11
                bit_pair_idx += 1
                if bit_pair == 0 or bit_pair == 1:
                    matrix[i, j] = 0
                elif bit_pair == 2:
                    matrix[i, j] = 1
                else:
                    matrix[i, j] = -1
        return matrix

    def aggregate_v_shares(self, v_shares: List[List[int]]) -> List[int]:
        if not v_shares:
            return []

        dimension = len(v_shares[0])
        aggregated: List[int] = []

        for idx in range(dimension):
            shares_for_coord = [
                Share(int(vector[idx]) % self.prime, participant_index + 1)
                for participant_index, vector in enumerate(v_shares)
            ]

            reconstructed = self.lagrange_interpolate(shares_for_coord)
            if reconstructed > self.prime // 2:
                reconstructed -= self.prime
            aggregated.append(int(reconstructed))

        return aggregated

    def shamir_share(self, secret: int, n: int, t: int) -> List[Share]:
        coefficients = [secret % self.prime] + [self.rng.randbelow(self.prime) for _ in range(t-1)]
        
        shares = []
        for i in range(1, n+1):
            value = 0
            for power, coeff in enumerate(coefficients):
                value = (value + coeff * pow(i, power, self.prime)) % self.prime
            shares.append(Share(value, i))
        return shares

    def share_vector(self, secret_vector: List[int], sigma_x: float = 1.0, sigma_y: float = 18.36) -> Tuple[Any, List[Any], List[Any]]:
        """ä¸ºå•ä¸ªå‚ä¸è€…çš„ç§˜å¯†å‘é‡ç”Ÿæˆä»½é¢"""
        d = len(secret_vector)
        
        # æ­¥éª¤1: ç”Ÿæˆå™ªå£°å‘é‡
        start_time = time.time()
        y_vector = self.rng.gaussian_vector(d, 0.0, sigma_y)
        step1_time = time.time() - start_time
        
        # æ­¥éª¤2: Shamirç§˜å¯†å…±äº«
        start_time = time.time()
        x_shares = [self.shamir_share(secret_vector[i], self.n, self.t) for i in range(d)]
        y_shares = [self.shamir_share(y_vector[i], self.n, self.t) for i in range(d)]
        step2_time = time.time() - start_time
        self.add_performance_stat("Shamirç§˜å¯†å…±äº«", step2_time, {
            "å¤šé¡¹å¼æ„é€  (ä¸ºxå’Œyçš„æ¯ä¸ªåˆ†é‡åˆ›å»ºt-1æ¬¡å¤šé¡¹å¼)": 2 * d,
            "ä»½é¢ç”Ÿæˆ (å¯¹æ¯ä¸ªå¤šé¡¹å¼ç”Ÿæˆnä¸ªä»½é¢ç‚¹)": 2 * d * self.n,
            "æ¨¡å¹‚è¿ç®— (è®¡ç®—i^power mod p,ç”¨äºå¤šé¡¹å¼æ±‚å€¼)": 2 * d * self.n * self.t,
            "æ¨¡ä¹˜æ³•è¿ç®— (å¤šé¡¹å¼ç³»æ•°ä¹˜æ³•,åœ¨æœ‰é™åŸŸGF(p)ä¸Š)": 2 * d * self.n * self.t
        })
        
        # æ­¥éª¤3: æ„å»ºMerkleæ ‘
        start_time = time.time()
        salt = self.rng.decimal_salt(128)
        leaf_data = []
        salts = []
        
        for participant in range(self.n):
            x_participant = [x_shares[i][participant].value for i in range(d)]
            y_participant = [y_shares[i][participant].value for i in range(d)]
            participant_salt = self.rng.decimal_salt(128)
            salts.append(participant_salt)
            leaf = '|'.join(map(str, x_participant + y_participant)) + '|' + participant_salt
            leaf_hash = MerkleTree.hash_item(leaf)
            leaf_data.append(leaf_hash)
        
        merkle_tree = MerkleTree(leaf_data)
        h = merkle_tree.root.hash
        step3_time = time.time() - start_time
        
        # è®¡ç®—Merkleæ ‘çš„å“ˆå¸Œæ¬¡æ•°
        merkle_hashes = self.n  # å¶å­èŠ‚ç‚¹å“ˆå¸Œ
        tree_levels = 0
        nodes = self.n
        while nodes > 1:
            nodes = (nodes + 1) // 2
            merkle_hashes += nodes
            tree_levels += 1
        
        self.add_performance_stat("Merkleæ ‘æ„å»º", step3_time, {
            "å¶å­èŠ‚ç‚¹æ•° (æ¯ä¸ªå‚ä¸è€…å¯¹åº”ä¸€ä¸ªå¶å­)": self.n,
            "æ ‘çš„å±‚æ•° (äºŒå‰æ ‘é«˜åº¦=logâ‚‚(n))": tree_levels,
            "SHA-256å“ˆå¸Œ (å¶å­å“ˆå¸Œ+æ‰€æœ‰å†…éƒ¨èŠ‚ç‚¹å“ˆå¸Œ)": merkle_hashes,
            "éšæœºç›ç”Ÿæˆ (128ä½éšæœºæ•°,é˜²æ­¢å¶å­ç¢°æ’)": self.n
        })
        
        # æ­¥éª¤4: ç”ŸæˆæŒ‘æˆ˜çŸ©é˜µR
        start_time = time.time()
        R = self.generate_random_matrix(d, d, h)
        spectral_norm = self.compute_spectral_norm(R)
        bound = self.compute_bound(R, sigma_x, sigma_y, d)
        step4_time = time.time() - start_time
        self.add_performance_stat("æŒ‘æˆ˜çŸ©é˜µä¸ç•Œé™è®¡ç®—", step4_time, {
            "çŸ©é˜µå…ƒç´ ç”Ÿæˆ (dÃ—dçŸ©é˜µ,å…ƒç´ ä¸º{-1,0,1})": d * d,
            "SHAKE-128æ‘˜è¦ (å¯æ‰©å±•è¾“å‡ºå‡½æ•°,ç”Ÿæˆä¼ªéšæœºå­—èŠ‚)": d * d // 4 + 1,
            "SVDåˆ†è§£ (å¥‡å¼‚å€¼åˆ†è§£,O(dÂ³)å¤æ‚åº¦)": 1,
            "è°±èŒƒæ•°è®¡ç®— (å–æœ€å¤§å¥‡å¼‚å€¼Ïƒâ‚,è¡¡é‡çŸ©é˜µæ‹‰ä¼¸èƒ½åŠ›)": 1
        })
        
        # æ­¥éª¤5: è®¡ç®—éªŒè¯å‘é‡v
        start_time = time.time()
        v_shares = []
        half_prime = self.prime // 2
        matrix_mults = 0
        modular_ops = 0
        
        for participant in range(self.n):
            x_participant = [x_shares[i][participant].value for i in range(d)]
            y_participant = [y_shares[i][participant].value for i in range(d)]
            v_i = []
            for i in range(d):
                v_elem = int(y_participant[i]) % self.prime
                modular_ops += 1
                for j in range(d):
                    v_elem = (v_elem + int(R[i][j]) * int(x_participant[j])) % self.prime
                    matrix_mults += 1
                    modular_ops += 2
                
                if v_elem > half_prime:
                    v_elem = v_elem - self.prime
                    
                v_i.append(int(v_elem))
            v_shares.append(v_i)
        
        aggregated_v = self.aggregate_v_shares(v_shares)

        step5_time = time.time() - start_time
        self.add_performance_stat("éªŒè¯å‘é‡è®¡ç®—", step5_time, {
            "çŸ©é˜µå‘é‡ä¹˜æ³• (è®¡ç®—RÂ·x_i,æ¯ä¸ªå‚ä¸è€…ä¸€æ¬¡)": self.n,
            "æ ‡é‡ä¹˜æ³• (çŸ©é˜µå…ƒç´ Ã—å‘é‡å…ƒç´ ,å…±nÃ—dÃ—dæ¬¡)": matrix_mults,
            "æ¨¡è¿ç®— (åŠ æ³•+å–æ¨¡,ä¿æŒåœ¨æœ‰é™åŸŸGF(p)å†…)": modular_ops,
            "ä¸­å¿ƒåŒ–è½¬æ¢ (å°†[0,p)æ˜ å°„åˆ°[-p/2,p/2],ä¾¿äºèŒƒæ•°è®¡ç®—)": self.n * d
        })
        
        # å‡†å¤‡è¯æ˜æ•°æ®
        share_data = []
        for participant in range(self.n):
            merkle_proof = merkle_tree.get_proof(participant)
            share_info = {
                'x_shares': [x_shares[i][participant].value for i in range(d)],
                'y_shares': [y_shares[i][participant].value for i in range(d)],
                'salt': salts[participant],
                'merkle_proof': merkle_proof
            }
            share_data.append(share_info)
        
        public_proof = {
            'h': h,
            'v_shares': v_shares,
            'aggregated_v': aggregated_v,
            'R': R.tolist(),
            'bound': bound,
            'spectral_norm': spectral_norm,
            'sigma_x': sigma_x,
            'sigma_y': sigma_y,
            'main_salt': salt
        }
        
        return public_proof, share_data, x_shares

    def verify_share(self, participant_id: int, public_proof: dict, participant_proof: dict) -> Tuple[bool, float, Dict[str, int]]:
        """
        éªŒè¯æ¥æ”¶åˆ°çš„ä»½é¢
        
        è¿”å›: (éªŒè¯ç»“æœ, è€—æ—¶, æ“ä½œç»Ÿè®¡)
        """
        start_time = time.time()
        operations = {}
        
        d = len(participant_proof['x_shares'])
        
        # æ­¥éª¤1: éªŒè¯Merkle proof
        leaf = '|'.join(map(str, participant_proof['x_shares'] + participant_proof['y_shares'])) + '|' + participant_proof['salt']
        leaf_hash = MerkleTree.hash_item(leaf)
        operations['SHA-256å¶å­å“ˆå¸Œ (é‡æ„å‚ä¸è€…çš„å¶å­èŠ‚ç‚¹å“ˆå¸Œ)'] = 1
        
        merkle_proof_len = len(participant_proof['merkle_proof'])
        if not MerkleTree.verify_proof(leaf_hash, participant_proof['merkle_proof'], public_proof['h']):
            duration = time.time() - start_time
            operations['SHA-256è·¯å¾„å“ˆå¸Œ (éªŒè¯ä»å¶å­åˆ°æ ¹çš„è·¯å¾„)'] = merkle_proof_len
            return False, duration, operations
        
        operations['SHA-256è·¯å¾„å“ˆå¸Œ (éªŒè¯ä»å¶å­åˆ°æ ¹çš„è·¯å¾„)'] = merkle_proof_len
        operations['Merkleè¯æ˜éªŒè¯ (æ£€æŸ¥ä»½é¢å±äºæ‰¿è¯ºæ ‘)'] = 1
        
        # æ­¥éª¤2: éªŒè¯çº¿æ€§å…³ç³»
        R = np.array(public_proof['R'], dtype=object)
        x_share = np.array(participant_proof['x_shares'], dtype=object)
        y_share = np.array(participant_proof['y_shares'], dtype=object)
        
        v_calc = np.zeros(len(x_share), dtype=object)
        scalar_mults = 0
        modular_ops = 0
        
        for i in range(len(v_calc)):
            v_calc[i] = int(y_share[i])
            modular_ops += 1
            for j in range(len(x_share)):
                v_calc[i] = (v_calc[i] + int(R[i][j]) * int(x_share[j])) % self.prime
                scalar_mults += 1
                modular_ops += 2
        
        operations['æ ‡é‡ä¹˜æ³• (è®¡ç®—RÂ·x_i,çŸ©é˜µå…ƒç´ Ã—å‘é‡å…ƒç´ )'] = scalar_mults
        operations['æ¨¡è¿ç®— (åŠ æ³•å’Œå–æ¨¡,ä¿æŒåœ¨æœ‰é™åŸŸå†…)'] = modular_ops
        
        v_public = np.array(public_proof['v_shares'][participant_id-1], dtype=object);
        
        for i in range(len(v_calc)):
            if int(v_calc[i]) % self.prime != int(v_public[i]) % self.prime:
                duration = time.time() - start_time
                return False, duration, operations
        
        operations['çº¿æ€§å…³ç³»æ£€æŸ¥ (éªŒè¯v_i=RÂ·x_i+y_iæ˜¯å¦æˆç«‹)'] = len(v_calc)
        
        # æ­¥éª¤3: éªŒè¯èšåˆå‘é‡çš„èŒƒæ•°
        aggregated_v = public_proof.get('aggregated_v')
        if aggregated_v is None:
            aggregated_v = self.aggregate_v_shares(public_proof['v_shares'])

        half_prime = self.prime // 2
        aggregated_centered: List[float] = []

        for val in aggregated_v:
            int_val = int(val) % self.prime
            if int_val > half_prime:
                int_val = int_val - self.prime
            aggregated_centered.append(float(int_val))

        operations['ä¸­å¿ƒåŒ–è½¬æ¢ (èšåˆéªŒè¯å‘é‡)'] = len(aggregated_centered)

        norm = np.linalg.norm(aggregated_centered)
        operations['èŒƒæ•°è®¡ç®— (èšåˆvå‘é‡||v||â‚‚)'] = 1
        
        duration = time.time() - start_time
        
        if norm > public_proof['bound']:
            return False, duration, operations
        
        return True, duration, operations
    
    def reconstruct_secret(self, x_shares_list: List[List[Share]], participant_indices: List[int]) -> Tuple[List[int], float, Dict[str, int]]:
        """
        ä½¿ç”¨æ‹‰æ ¼æœ—æ—¥æ’å€¼é‡æ„ç§˜å¯†å‘é‡
        
        å‚æ•°:
        x_shares_list: æ¯ä¸ªç»´åº¦çš„æ‰€æœ‰ä»½é¢åˆ—è¡¨ [dim0_shares, dim1_shares, ...]
        participant_indices: å‚ä¸é‡æ„çš„å‚ä¸è€…ç´¢å¼•ï¼ˆè‡³å°‘tä¸ªï¼‰
        
        è¿”å›: (é‡æ„çš„ç§˜å¯†å‘é‡, è€—æ—¶, æ“ä½œç»Ÿè®¡)
        """
        start_time = time.time()
        operations = {}
        
        d = len(x_shares_list)
        secret_vector = []
        half_prime = self.prime // 2
        
        lagrange_interps = 0
        modular_inverses = 0
        modular_mults = 0
        
        for i in range(d):
            shares_to_use = [x_shares_list[i][idx] for idx in participant_indices[:self.t]]
            
            # ç»Ÿè®¡æ‹‰æ ¼æœ—æ—¥æ’å€¼çš„æ“ä½œ
            k = len(shares_to_use)
            for j in range(k):
                for m in range(k):
                    if j != m:
                        modular_mults += 2  # numeratorå’Œdenominatorè®¡ç®—
                modular_inverses += 1  # æ¯ä¸ªåŸºå‡½æ•°éœ€è¦ä¸€æ¬¡æ¨¡é€†
                modular_mults += 2  # yi * numerator * denominator_inv
            
            secret = self.lagrange_interpolate(shares_to_use)
            lagrange_interps += 1
            
            secret = secret % self.prime
            if secret > half_prime:
                secret = secret - self.prime
                
            secret_vector.append(int(secret))
        
        duration = time.time() - start_time
        
        operations['æ‹‰æ ¼æœ—æ—¥æ’å€¼ (å¤šé¡¹å¼æ’å€¼,æ¯ä¸ªç»´åº¦ä¸€æ¬¡)'] = lagrange_interps
        operations['æ¨¡é€†å…ƒè®¡ç®— (è´¹é©¬å°å®šç†a^(p-2) mod p,255ä½å¤§æ•°å¹‚è¿ç®—)'] = modular_inverses * d
        operations['æ¨¡ä¹˜æ³• (æ‹‰æ ¼æœ—æ—¥åŸºå‡½æ•°è®¡ç®—,æœ‰é™åŸŸä¹˜æ³•)'] = modular_mults
        operations['ä¸­å¿ƒåŒ–è½¬æ¢ (é‡æ„ç»“æœè½¬å›æœ‰ç¬¦å·è¡¨ç¤º)'] = d
        
        return secret_vector, duration, operations

class DistributedParticipant(threading.Thread):
    """åˆ†å¸ƒå¼å‚ä¸è€…"""
    
    def __init__(self, participant_id: int, n: int, t: int, d: int, 
                 network: NetworkSimulator,
                 sigma_x: float = 1.0, sigma_y: float = 18.36):
        super().__init__()
        self.participant_id = participant_id
        self.n = n
        self.t = t
        self.d = d
        self.network = network
        self.sigma_x = sigma_x
        self.sigma_y = sigma_y

        self.rng = SecureRandom(f"legacy-participant-{participant_id}")
        self.v3s = V3S(n, t, rng=self.rng.derive_child(f"legacy-v3s-core-{participant_id}"))
        self.secret_vector = None
        self.public_proof = None
        self.share_data = None
        self.noise_share_vector = None
        self.x_shares = None

        # å­˜å‚¨æ¥æ”¶åˆ°çš„ä»½é¢
        self.received_shares: Dict[int, Dict[str, Any]] = {}
        self.received_proofs: Dict[int, Dict[str, Any]] = {}
        self.received_share_packages: Dict[int, EncryptedSharePackage] = {}
        self.received_share_keys: Dict[int, bytes] = {}
        
        # æœ‰æ•ˆä»½é¢æ•°ç»„ï¼ˆéªŒè¯é€šè¿‡çš„ä»½é¢ï¼‰
        self.valid_shares = []  # å­˜å‚¨æœ‰æ•ˆçš„participant_idåˆ—è¡¨
        self.local_valid_ids: Set[int] = set()  # æœ¬åœ°åˆ¤å®šä¸ºæœ‰æ•ˆçš„å‘é€è€…
        self.received_validation_vectors: Dict[int, List[int]] = {}
        
        # æŠ•è¯‰ç›¸å…³
        self.complaints_sent = []      # æœ¬å‚ä¸è€…å‘é€çš„æŠ•è¯‰
        self.complaints_received = []  # æ¥æ”¶åˆ°çš„æŠ•è¯‰
        
        # ç›å€¼ç›¸å…³
        self.participant_salt = self.rng.decimal_salt(256)  # ç”Ÿæˆ256ä½éšæœºç›å€¼ salt_i
        self.received_salts = {}  # å­˜å‚¨æ¥æ”¶åˆ°çš„å…¶ä»–å‚ä¸è€…çš„ç›å€¼ {participant_id: salt}
        self.consensus_salt = None  # å…±è¯†ç›å€¼
        
        # éªŒè¯ç»Ÿè®¡
        self.verification_results = []
        self.verification_times = []
        self.verification_ops = []
        
        # é‡æ„ç»Ÿè®¡
        self.reconstruction_time = 0
        
        # å…¨å±€ç§˜å¯†ç›¸å…³
        self.aggregated_shares = None  # èšåˆåçš„ä»½é¢ï¼ˆæ‰€æœ‰æœ‰æ•ˆå‚ä¸è€…çš„ä»½é¢ä¹‹å’Œï¼‰
        self.global_secret = None      # é‡æ„çš„å…¨å±€ç§˜å¯†
        
        # å…¬é’¥ç›¸å…³
        self.public_matrix_A = None    # åŸºäºå…±è¯†ç›å€¼ç”Ÿæˆçš„å…¬å…±çŸ©é˜µA
        self.partial_public_key = None # éƒ¨åˆ†å…¬é’¥ b_i = A * s_i
        self.global_public_key = None  # å…¨å±€å…¬é’¥ b = sum(b_i)
        
        # å…¬é’¥ç”Ÿæˆç»Ÿè®¡
        self.public_key_generation_time = 0  # å…¨å±€å…¬é’¥ç”Ÿæˆæ€»æ—¶é—´
        
        # ç½‘ç»œé€šä¿¡ç»Ÿè®¡
        self.network_send_time = 0
        self.network_receive_time = 0
        self.network_ops = {}
        
        # åŒæ­¥æœºåˆ¶
        self.done_event = threading.Event()
        
        # ç”Ÿæˆå¹¶æ³¨å†Œç­¾åå¯†é’¥ä¸KEMå¯†é’¥
        self.signing_private_key, self.signing_public_key = CryptoManager.generate_signature_keypair()
        self.kem_private_key, self.kem_public_key = CryptoManager.generate_kem_keypair()

        self.network.register_participant(
            self.participant_id,
            self.signing_public_key,
            self.kem_public_key,
        )
    
    def run(self):
        """å‚ä¸è€…ä¸»æµç¨‹"""
        try:
            # ç¬¬1æ­¥ï¼šç”Ÿæˆè‡ªå·±çš„ç§˜å¯†å‘é‡
            self.generate_secret()
            
            # ç¬¬2æ­¥ï¼šç”Ÿæˆä»½é¢å¹¶æ„å»ºMerkleæ ‘
            self.create_shares()
            
            # ç¬¬3æ­¥ï¼šåŠ å¯†å¹¶å‘é€ä»½é¢ç»™å…¶ä»–å‚ä¸è€…
            self.encrypt_and_send_shares()
            
            # ç¬¬4æ­¥ï¼šå¹¿æ’­å…¬å¼€è¯æ˜
            self.broadcast_public_proof()
            
            # ç¬¬5æ­¥ï¼šæ¥æ”¶å…¶ä»–å‚ä¸è€…çš„ä»½é¢å’Œè¯æ˜
            self.receive_and_verify_shares()
            
            self.done_event.set()
            
        except Exception as e:
            print(f"[Participant {self.participant_id}] Error: {e}")
            import traceback
            traceback.print_exc()
    
    def generate_secret(self):
        """ç”Ÿæˆè‡ªå·±çš„çŸ­ç§˜å¯†å‘é‡"""
        self.secret_vector = self.rng.gaussian_vector(self.d, 0.0, self.sigma_x)
        print(f"[Participant {self.participant_id}] Generated secret vector: {self.secret_vector}")
        print(f"[Participant {self.participant_id}] Generated participant salt: {self.participant_salt[:16]}...")
    
    def create_shares(self):
        """ä½¿ç”¨V3Såè®®åˆ›å»ºä»½é¢"""
        print(f"[Participant {self.participant_id}] Creating shares...")
        start_time = time.time()
        
        self.public_proof, self.share_data, self.x_shares = self.v3s.share_vector(
            self.secret_vector, self.sigma_x, self.sigma_y
        )

        if self.share_data is not None:
            own_index = self.participant_id - 1
            if 0 <= own_index < len(self.share_data):
                self.noise_share_vector = [int(val) for val in self.share_data[own_index]['y_shares']]
        
        duration = time.time() - start_time
        print(f"[Participant {self.participant_id}] Shares created in {duration*1000:.2f} ms")
        print(f"[Participant {self.participant_id}] Merkle root: {self.public_proof['h'][:16]}...")
    
    def encrypt_and_send_shares(self):
        """åŠ å¯†å¹¶å‘é€ä»½é¢ç»™å…¶ä»–å‚ä¸è€…"""
        print(f"[Participant {self.participant_id}] Encrypting and sending shares with KEM + signatures...")

        send_start_time = time.time()
        shares_sent = 0
        encryptions_performed = 0
        kem_ops = 0
        signature_ops = 0

        for receiver_id in range(1, self.n + 1):
            if receiver_id == self.participant_id:
                continue

            share_info = self.share_data[receiver_id - 1]
            receiver_kem_public = self.network.get_kem_public_key(receiver_id)
            context = f"v3s-share-{self.participant_id}-{receiver_id}".encode()
            symmetric_key, kem_public = CryptoManager.encapsulate_key(receiver_kem_public, context)
            kem_ops += 1

            encrypted_data, nonce = CryptoManager.encrypt_data(share_info, symmetric_key)
            encryptions_performed += 1

            key_binding = CryptoManager.serialize_key_binding(self.participant_id, receiver_id, symmetric_key)
            key_signature = CryptoManager.sign_message(key_binding, self.signing_private_key)
            signature_ops += 1

            package = EncryptedSharePackage(
                sender_id=self.participant_id,
                receiver_id=receiver_id,
                encrypted_data=encrypted_data,
                nonce=nonce,
                kem_public=kem_public,
                key_signature=key_signature,
                signature=b"",
            )

            serialized = CryptoManager.serialize_share_package(package)
            signature = CryptoManager.sign_message(serialized, self.signing_private_key)
            package.signature = signature
            signature_ops += 1

            self.network.send_encrypted_share(package)
            shares_sent += 1

        self.network_send_time = time.time() - send_start_time
        self.network_ops['å‘é€åŠ å¯†ä»½é¢ (KEM+AES-GCM)'] = shares_sent
        self.network_ops['AES-GCMåŠ å¯†æ“ä½œ (å¯¹ç§°åŠ å¯†ä¿æŠ¤ä»½é¢éšç§)'] = encryptions_performed
        self.network_ops['X25519å°è£…æ“ä½œ (KEM)'] = kem_ops
        self.network_ops['Ed25519ç­¾å (ä»½é¢åŒ…+å¯†é’¥ç»‘å®š)'] = signature_ops

        print(
            f"[Participant {self.participant_id}] Sent {self.n-1} encrypted shares "
            f"({self.network_send_time*1000:.2f} ms, KEM ops: {kem_ops}, signatures: {signature_ops})"
        )
    
    def broadcast_public_proof(self):
        """å¹¿æ’­ç›å€¼å’Œå…¬å¼€è¯æ˜"""
        print(f"[Participant {self.participant_id}] Broadcasting public proof...")
        
        broadcast_start_time = time.time()
        
        proof = PublicProof(
            participant_id=self.participant_id,
            merkle_root=self.public_proof['h'],
            salt=self.public_proof['main_salt'],
            participant_salt=self.participant_salt,  # å¹¿æ’­å‚ä¸è€…ç›å€¼ salt_i
            v_shares=self.public_proof['v_shares'],
            aggregated_v=self.public_proof['aggregated_v'],
            R=self.public_proof['R'],
            bound=self.public_proof['bound'],
            spectral_norm=self.public_proof['spectral_norm']
        )
        
        self.network.broadcast_proof(proof)
        
        broadcast_time = time.time() - broadcast_start_time
        self.network_send_time += broadcast_time
        self.network_ops['å¹¿æ’­å…¬å¼€è¯æ˜ (Merkleæ ¹+éªŒè¯å‘é‡+æŒ‘æˆ˜çŸ©é˜µ)'] = 1
        
        print(f"[Participant {self.participant_id}] Public proof broadcasted ({broadcast_time*1000:.2f} ms)")
    
    def receive_and_verify_shares(self):
        """æ¥æ”¶å¹¶éªŒè¯å…¶ä»–å‚ä¸è€…çš„ä»½é¢"""
        self.valid_shares = []
        self.local_valid_ids.clear()
        self.received_validation_vectors = {}

        print(f"[Participant {self.participant_id}] Receiving shares from other participants...")

        receive_start_time = time.time()

        time.sleep(1.0)
        encrypted_packages = self.network.receive_encrypted_shares(self.participant_id)

        receive_shares_time = time.time() - receive_start_time

        print(f"[Participant {self.participant_id}] Received {len(encrypted_packages)} encrypted shares")

        decrypt_start_time = time.time()
        decryptions_performed = 0
        kem_decaps_ops = 0
        signature_verifications = 0

        for package in encrypted_packages:
            try:
                context = f"v3s-share-{package.sender_id}-{self.participant_id}".encode()
                symmetric_key = CryptoManager.decapsulate_key(
                    package.kem_public,
                    self.kem_private_key,
                    context,
                )
                kem_decaps_ops += 1

                sender_public_key = self.network.get_signing_public_key(package.sender_id)
                key_binding = CryptoManager.serialize_key_binding(package.sender_id, self.participant_id, symmetric_key)
                key_signature_ok = CryptoManager.verify_signature(
                    package.key_signature,
                    key_binding,
                    sender_public_key,
                )
                signature_verifications += 1

                if not key_signature_ok:
                    self.local_valid_ids.discard(package.sender_id)
                    evidence_payload = CryptoManager.serialize_complaint_evidence(package, symmetric_key)
                    complaint_signature = CryptoManager.sign_message(evidence_payload, self.signing_private_key)
                    complaint = Complaint(
                        complainer_id=self.participant_id,
                        accused_id=package.sender_id,
                        reason="Invalid key binding signature",
                        timestamp=time.time(),
                        evidence_package=package,
                        symmetric_key=symmetric_key,
                        complainer_signature=complaint_signature,
                        sender_key_signature=package.key_signature,
                    )
                    self.network.broadcast_complaint(complaint)
                    self.complaints_sent.append(complaint)
                    print(
                        f"[Participant {self.participant_id}] âœ— Invalid key signature on share from Participant {package.sender_id}"
                    )
                    print(
                        f"[Participant {self.participant_id}] ğŸ“¢ Broadcasting complaint against Participant {package.sender_id}"
                    )
                    continue

                serialized = CryptoManager.serialize_share_package(package)
                signature_ok = CryptoManager.verify_signature(
                    package.signature,
                    serialized,
                    sender_public_key,
                )
                signature_verifications += 1

                if not signature_ok:
                    self.local_valid_ids.discard(package.sender_id)
                    evidence_payload = CryptoManager.serialize_complaint_evidence(package, symmetric_key)
                    complaint_signature = CryptoManager.sign_message(evidence_payload, self.signing_private_key)
                    complaint = Complaint(
                        complainer_id=self.participant_id,
                        accused_id=package.sender_id,
                        reason="Invalid share signature",
                        timestamp=time.time(),
                        evidence_package=package,
                        symmetric_key=symmetric_key,
                        complainer_signature=complaint_signature,
                        sender_key_signature=package.key_signature,
                    )
                    self.network.broadcast_complaint(complaint)
                    self.complaints_sent.append(complaint)
                    print(
                        f"[Participant {self.participant_id}] âœ— Invalid signature on share from Participant {package.sender_id}"
                    )
                    print(
                        f"[Participant {self.participant_id}] ğŸ“¢ Broadcasting complaint against Participant {package.sender_id}"
                    )
                    continue

                self.received_share_packages[package.sender_id] = package
                self.received_share_keys[package.sender_id] = symmetric_key

                share_info = CryptoManager.decrypt_data(
                    package.encrypted_data,
                    package.nonce,
                    symmetric_key,
                )

                self.received_shares[package.sender_id] = share_info
                decryptions_performed += 1
                print(f"[Participant {self.participant_id}] Decrypted share from Participant {package.sender_id}")

            except Exception as e:
                self.local_valid_ids.discard(package.sender_id)
                print(f"[Participant {self.participant_id}] Failed to process share from {package.sender_id}: {e}")

        decrypt_time = time.time() - decrypt_start_time

        receive_proofs_start_time = time.time()
        all_proofs = self.network.receive_all_proofs(self.participant_id, self.n)
        receive_proofs_time = time.time() - receive_proofs_start_time

        self.network_receive_time = receive_shares_time + decrypt_time + receive_proofs_time
        self.network_ops['æ¥æ”¶åŠ å¯†ä»½é¢ (ç½‘ç»œæ¥æ”¶+é˜Ÿåˆ—æ“ä½œ)'] = len(encrypted_packages)
        self.network_ops['AES-GCMè§£å¯†æ“ä½œ (è§£å¯†æ¥æ”¶åˆ°çš„ä»½é¢)'] = decryptions_performed
        self.network_ops['X25519è§£å°è£…æ“ä½œ (KEM)'] = kem_decaps_ops
        self.network_ops['Ed25519éªŒç­¾ (ä»½é¢åŒ…+å¯†é’¥ç»‘å®š)'] = signature_verifications
        self.network_ops['æ¥æ”¶å…¬å¼€è¯æ˜ (å¹¿æ’­æ¶ˆæ¯æ¥æ”¶)'] = len(all_proofs)

        print(f"[Participant {self.participant_id}] Received {len(all_proofs)} public proofs ({self.network_receive_time*1000:.2f} ms total)")

        verified_count = 0
        failed_count = 0

        for proof in all_proofs:
            if proof.participant_id == self.participant_id:
                continue

            self.received_salts[proof.participant_id] = proof.participant_salt

            self.received_proofs[proof.participant_id] = {
                'h': proof.merkle_root,
                'v_shares': proof.v_shares,
                'aggregated_v': proof.aggregated_v,
                'R': proof.R,
                'bound': proof.bound,
                'spectral_norm': proof.spectral_norm,
                'sigma_x': self.sigma_x,
                'sigma_y': self.sigma_y
            }

            if proof.participant_id in self.received_shares:
                share_info = self.received_shares[proof.participant_id]
                public_proof = self.received_proofs[proof.participant_id]

                is_valid, duration, operations = self.v3s.verify_share(
                    self.participant_id,
                    public_proof,
                    share_info,
                )

                self.verification_results.append(is_valid)
                self.verification_times.append(duration)
                self.verification_ops.append(operations)

                if is_valid:
                    self.local_valid_ids.add(proof.participant_id)
                    verified_count += 1
                    print(
                        f"[Participant {self.participant_id}] âœ“ Verified share from Participant {proof.participant_id} ({duration*1000:.2f} ms)"
                    )
                else:
                    self.local_valid_ids.discard(proof.participant_id)
                    failed_count += 1
                    package = self.received_share_packages.get(proof.participant_id)
                    symmetric_key = self.received_share_keys.get(proof.participant_id)
                    complaint_signature = None

                    if package is not None and symmetric_key is not None:
                        evidence_payload = CryptoManager.serialize_complaint_evidence(package, symmetric_key)
                        complaint_signature = CryptoManager.sign_message(evidence_payload, self.signing_private_key)

                    complaint = Complaint(
                        complainer_id=self.participant_id,
                        accused_id=proof.participant_id,
                        reason="Share verification failed",
                        timestamp=time.time(),
                        evidence_package=package,
                        symmetric_key=symmetric_key,
                        complainer_signature=complaint_signature,
                        sender_key_signature=getattr(package, "key_signature", None),
                    )
                    self.network.broadcast_complaint(complaint)
                    self.complaints_sent.append(complaint)
                    print(
                        f"[Participant {self.participant_id}] âœ— Failed to verify share from Participant {proof.participant_id}"
                    )
                    print(
                        f"[Participant {self.participant_id}] ğŸ“¢ Broadcasting complaint against Participant {proof.participant_id}"
                    )

        print(
            f"[Participant {self.participant_id}] Verification complete: {verified_count} valid, {failed_count} invalid (out of {len(all_proofs)-1})"
        )

        print(f"[Participant {self.participant_id}] Listening for complaints...")
        time.sleep(0.5)
        received_complaints = self.network.receive_complaints(self.participant_id)

        if received_complaints:
            print(f"[Participant {self.participant_id}] Received {len(received_complaints)} complaint(s)")

            for complaint in received_complaints:
                self.complaints_received.append(complaint)
                evidence_verified = False

                if (
                    complaint.evidence_package is not None
                    and complaint.symmetric_key is not None
                    and complaint.complainer_signature is not None
                ):
                    package = complaint.evidence_package
                    symmetric_key = complaint.symmetric_key

                    serialized_package = CryptoManager.serialize_share_package(package)
                    sender_pub = self.network.get_signing_public_key(package.sender_id)
                    package_signature_ok = CryptoManager.verify_signature(
                        package.signature,
                        serialized_package,
                        sender_pub,
                    )

                    complainer_pub = self.network.get_signing_public_key(complaint.complainer_id)
                    evidence_payload = CryptoManager.serialize_complaint_evidence(package, symmetric_key)
                    complainer_signature_ok = CryptoManager.verify_signature(
                        complaint.complainer_signature,
                        evidence_payload,
                        complainer_pub,
                    )

                    sender_key_signature = complaint.sender_key_signature or package.key_signature
                    key_signature_ok = False
                    if sender_key_signature is not None:
                        key_binding = CryptoManager.serialize_key_binding(
                            package.sender_id,
                            package.receiver_id,
                            symmetric_key,
                        )
                        key_signature_ok = CryptoManager.verify_signature(
                            sender_key_signature,
                            key_binding,
                            sender_pub,
                        )

                    if package_signature_ok and complainer_signature_ok and key_signature_ok:
                        try:
                            share_info = CryptoManager.decrypt_data(
                                package.encrypted_data,
                                package.nonce,
                                symmetric_key,
                            )
                        except Exception as exc:
                            print(
                                f"[Participant {self.participant_id}] âš ï¸  Failed to decrypt evidence from complaint against Participant {complaint.accused_id}: {exc}"
                            )
                        else:
                            if package.sender_id == self.participant_id and self.public_proof is not None:
                                public_proof = self.public_proof
                            else:
                                public_proof = self.received_proofs.get(package.sender_id)

                            if public_proof is None:
                                print(
                                    f"[Participant {self.participant_id}] âš ï¸  Missing public proof for Participant {package.sender_id}, cannot verify complaint evidence"
                                )
                            else:
                                is_valid, _, _ = self.v3s.verify_share(
                                    complaint.complainer_id,
                                    public_proof,
                                    share_info,
                                )
                                if not is_valid:
                                    evidence_verified = True
                                else:
                                    print(
                                        f"[Participant {self.participant_id}] â„¹ï¸  Complaint evidence indicates share from Participant {package.sender_id} is valid"
                                    )
                    else:
                        if not package_signature_ok:
                            print(
                                f"[Participant {self.participant_id}] âš ï¸  Invalid package signature in complaint against Participant {complaint.accused_id}"
                            )
                        elif not key_signature_ok:
                            print(
                                f"[Participant {self.participant_id}] âš ï¸  Invalid key signature in complaint against Participant {complaint.accused_id}"
                            )
                        else:
                            print(
                                f"[Participant {self.participant_id}] âš ï¸  Invalid complainer signature in complaint against Participant {complaint.accused_id}"
                            )

                if evidence_verified:
                    if complaint.accused_id in self.local_valid_ids:
                        self.local_valid_ids.remove(complaint.accused_id)
                        print(
                            f"[Participant {self.participant_id}] âš ï¸  Revoked trust in Participant {complaint.accused_id} after verified complaint by Participant {complaint.complainer_id}"
                        )
                else:
                    print(
                        f"[Participant {self.participant_id}] â„¹ï¸  Complaint from Participant {complaint.complainer_id} lacked verifiable evidence"
                    )

        self.broadcast_and_collect_validation_vectors()

        print(f"[Participant {self.participant_id}] Final valid shares (intersection): {self.valid_shares} ({len(self.valid_shares)} participants)")

        self.compute_consensus_salt()
        self.aggregate_and_reconstruct_global_secret()
    
    def broadcast_and_collect_validation_vectors(self) -> None:
        """å¹¿æ’­æœ¬åœ°éªŒè¯ç»“æœå¹¶ä¸å…¶ä»–å‚ä¸è€…æ±‚äº¤é›†."""

        accepted_ids = set(self.local_valid_ids)
        accepted_ids.add(self.participant_id)

        validation_vector = ValidationVector(
            participant_id=self.participant_id,
            accepted_ids=sorted(accepted_ids),
        )

        send_start = time.time()
        self.network.broadcast_validation_vector(validation_vector)
        broadcast_duration = time.time() - send_start
        self.network_send_time += broadcast_duration
        self.network_ops['å¹¿æ’­éªŒè¯ç»“æœ (valid_i é›†åˆ)'] = 1

        self.received_validation_vectors[self.participant_id] = list(validation_vector.accepted_ids)

        time.sleep(0.2)
        receive_start = time.time()
        vectors = self.network.receive_validation_vectors(self.participant_id, self.n)
        receive_duration = time.time() - receive_start
        self.network_receive_time += receive_duration

        for vector in vectors:
            self.received_validation_vectors[vector.participant_id] = list(vector.accepted_ids)

        if len(self.received_validation_vectors) < self.n:
            print(
                f"[Participant {self.participant_id}] âš ï¸  Received validation vectors from {len(self.received_validation_vectors)} participants (expected {self.n})"
            )

        if self.received_validation_vectors:
            common_valid = set(range(1, self.n + 1))
            common_valid.discard(self.participant_id)
            for accepted_ids in self.received_validation_vectors.values():
                common_valid &= set(accepted_ids)
        else:
            common_valid = set(self.local_valid_ids)

        self.valid_shares = sorted(common_valid)
        self.network_ops['æ¥æ”¶éªŒè¯ç»“æœ (valid_i é›†åˆ)'] = len(vectors)

    def compute_consensus_salt(self):
        """æ ¹æ®æœ‰æ•ˆå‚ä¸è€…æ•°ç»„è®¡ç®—å…±è¯†ç›å€¼"""
        print(f"[Participant {self.participant_id}] Computing consensus salt...")
        
        # æ”¶é›†æœ‰æ•ˆå‚ä¸è€…çš„ç›å€¼ï¼ˆæŒ‰participant_idæ’åºä»¥ç¡®ä¿ä¸€è‡´æ€§ï¼‰
        valid_salts = []
        
        # å°†è‡ªå·±çš„ç›å€¼ä¹ŸåŠ å…¥ï¼ˆå¦‚æœè‡ªå·±åœ¨æœ‰æ•ˆä»½é¢ä¸­ï¼‰
        # æ³¨æ„ï¼švalid_shareså­˜å‚¨çš„æ˜¯å…¶ä»–å‚ä¸è€…çš„IDï¼Œéœ€è¦åˆ¤æ–­è‡ªå·±æ˜¯å¦åº”è¯¥åŒ…å«
        # åœ¨æ­£å¸¸æƒ…å†µä¸‹ï¼Œæ¯ä¸ªå‚ä¸è€…éƒ½åº”è¯¥åŒ…å«è‡ªå·±çš„ç›å€¼
        sorted_valid_ids = sorted(self.valid_shares)
        
        # å¦‚æœè‡ªå·±çš„IDä¸åœ¨valid_sharesä¸­ä½†è‡ªå·±æ˜¯è¯šå®çš„ï¼Œåº”è¯¥åŠ å…¥è‡ªå·±
        # è¿™é‡Œæˆ‘ä»¬æ ¹æ®ä¸šåŠ¡é€»è¾‘ï¼šåªæœ‰å…¶ä»–å‚ä¸è€…éªŒè¯é€šè¿‡çš„æ‰åœ¨valid_sharesä¸­
        # æ‰€ä»¥æˆ‘ä»¬éœ€è¦åŒæ—¶è€ƒè™‘è‡ªå·±çš„ç›å€¼
        all_valid_ids = sorted(set(sorted_valid_ids + [self.participant_id]))
        
        for pid in all_valid_ids:
            if pid == self.participant_id:
                valid_salts.append(self.participant_salt)
            elif pid in self.received_salts:
                valid_salts.append(self.received_salts[pid])
            else:
                print(f"[Participant {self.participant_id}] âš ï¸  Warning: Salt for Participant {pid} not found!")
        
        # æ‹¼æ¥æ‰€æœ‰ç›å€¼å¹¶è®¡ç®—å“ˆå¸Œ
        concatenated_salts = '||'.join(valid_salts)
        
        # ä½¿ç”¨SHA-256ä½œä¸ºHsaltå“ˆå¸Œå‡½æ•°
        self.consensus_salt = hashlib.sha256(concatenated_salts.encode()).hexdigest()
        
        print(f"[Participant {self.participant_id}] Consensus salt computed from {len(all_valid_ids)} participants: {self.consensus_salt[:16]}...")
        print(f"[Participant {self.participant_id}] Valid participant IDs: {all_valid_ids}")
    
    def aggregate_and_reconstruct_global_secret(self):
        """èšåˆæ‰€æœ‰æœ‰æ•ˆä»½é¢å¹¶é‡æ„å…¨å±€ç§˜å¯†"""
        print(f"[Participant {self.participant_id}] Aggregating shares for global secret reconstruction...")
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æœ‰æ•ˆä»½é¢ï¼ˆè‡³å°‘è¾¾åˆ°é˜ˆå€¼ï¼‰
        all_valid_ids = sorted(set(self.valid_shares + [self.participant_id]))
        
        if len(all_valid_ids) < self.t:
            print(f"[Participant {self.participant_id}] âš ï¸  Insufficient valid shares ({len(all_valid_ids)} < {self.t}), cannot reconstruct global secret")
            return
        
        # æ­¥éª¤1: è®¡ç®—è‡ªå·±ä½ç½®çš„èšåˆä»½é¢
        # share_i(S_global) = share_i(S_1) + share_i(S_2) + ... + share_i(S_n)
        aggregation_start = time.time()
        
        my_position = self.participant_id - 1
        aggregated_shares_d_values = []
        
        for dim in range(self.d):
            # ä»è‡ªå·±çš„ x_shares ä¸­è·å–è‡ªå·±ä½ç½®çš„ä»½é¢å€¼ï¼ˆè‡ªå·±çš„ç§˜å¯†ï¼‰
            my_share_value = self.x_shares[dim][my_position].value
            aggregated_value = my_share_value
            
            # ç´¯åŠ æ‰€æœ‰æœ‰æ•ˆå‚ä¸è€…å‘ç»™æˆ‘çš„ä»½é¢
            for valid_pid in self.valid_shares:
                if valid_pid in self.received_shares:
                    share_info = self.received_shares[valid_pid]
                    # share_info['x_shares'][dim] æ˜¯å‚ä¸è€…valid_pidå‘ç»™æˆ‘çš„ç¬¬dimç»´çš„ä»½é¢
                    aggregated_value = (aggregated_value + share_info['x_shares'][dim]) % self.v3s.prime
            
            aggregated_shares_d_values.append(aggregated_value)
        
        aggregation_time = time.time() - aggregation_start
        self.aggregated_shares = aggregated_shares_d_values
        print(f"[Participant {self.participant_id}] Computed aggregated share at own position ({aggregation_time*1000:.2f} ms)")
        
        # æ­¥éª¤2: å¹¿æ’­è‡ªå·±çš„èšåˆä»½é¢
        broadcast_start = time.time()
        agg_share = AggregatedShare(
            participant_id=self.participant_id,
            aggregated_values=aggregated_shares_d_values
        )
        self.network.broadcast_aggregated_share(agg_share)
        broadcast_time = time.time() - broadcast_start
        print(f"[Participant {self.participant_id}] Broadcasted aggregated share ({broadcast_time*1000:.2f} ms)")
        
        # æ­¥éª¤3: æ¥æ”¶å…¶ä»–å‚ä¸è€…çš„èšåˆä»½é¢
        time.sleep(0.5)  # ç­‰å¾…å…¶ä»–å‚ä¸è€…å¹¿æ’­
        receive_start = time.time()
        received_agg_shares = self.network.receive_aggregated_shares(self.participant_id, len(all_valid_ids))
        receive_time = time.time() - receive_start
        print(f"[Participant {self.participant_id}] Received {len(received_agg_shares)} aggregated shares ({receive_time*1000:.2f} ms)")
        
        # æ­¥éª¤4: ä½¿ç”¨Reedâ€“Solomonçº é”™+æ’å€¼é‡æ„å…¨å±€ç§˜å¯†
        reconstruction_start = time.time()
        
        # æ”¶é›†è‡³å°‘tä¸ªå‚ä¸è€…çš„èšåˆä»½é¢
        available_agg_shares = {}
        available_agg_shares[self.participant_id] = aggregated_shares_d_values
        
        for agg_share in received_agg_shares:
            if agg_share.participant_id in all_valid_ids:
                available_agg_shares[agg_share.participant_id] = agg_share.aggregated_values
        
        if len(available_agg_shares) < self.t:
            print(f"[Participant {self.participant_id}] âš ï¸  Insufficient aggregated shares ({len(available_agg_shares)} < {self.t})")
            return
        
        participants_used = sorted(available_agg_shares.keys())
        correctable_errors = max(0, (len(participants_used) - self.t) // 2)
        
        global_secret_vector = []
        
        for dim in range(self.d):
            shares_for_dim = [Share(value=available_agg_shares[pid][dim], index=pid) for pid in participants_used]

            try:
                secret_dim = self.v3s.reed_solomon_reconstruct(shares_for_dim)
            except ValueError:
                print(f"[Participant {self.participant_id}] âŒ Reedâ€“Solomon decoding failed (errors > {correctable_errors})")
                print(f"[Participant {self.participant_id}] Aborting DKG: insufficient clean shares to reconstruct dimension {dim}")
                self.reconstruction_time = aggregation_time + broadcast_time + receive_time + (time.time() - reconstruction_start)
                self.done_event.set()
                raise
            
            # ä¸­å¿ƒåŒ–è½¬æ¢
            half_prime = self.v3s.prime // 2
            if secret_dim > half_prime:
                secret_dim = secret_dim - self.v3s.prime
            
            global_secret_vector.append(int(secret_dim))
        
        reconstruction_time = time.time() - reconstruction_start
        self.reconstruction_time = aggregation_time + broadcast_time + receive_time + reconstruction_time
        self.global_secret = global_secret_vector
        
        # è®¡ç®—å…¨å±€ç§˜å¯†çš„èŒƒæ•°
        global_norm = np.linalg.norm(global_secret_vector)
        
        print(f"[Participant {self.participant_id}] âœ“ Reconstructed global secret: {global_secret_vector}")
        print(f"[Participant {self.participant_id}] Global secret norm: ||S_global|| = {global_norm:.4f}")
        print(f"[Participant {self.participant_id}] Used {len(participants_used)} participants: {participants_used}")
        print(f"[Participant {self.participant_id}] Reedâ€“Solomon correctable errors â‰¤ {correctable_errors}")
        print(f"[Participant {self.participant_id}] Total reconstruction time: {self.reconstruction_time*1000:.2f} ms")
        
        # æ­¥éª¤5: åŸºäºå…±è¯†ç›å€¼ç”Ÿæˆå…¬å…±çŸ©é˜µAå¹¶è®¡ç®—éƒ¨åˆ†å…¬é’¥
        self.generate_public_matrix_and_compute_keys()
    
    def generate_public_matrix_and_compute_keys(self):
        """åŸºäºå…±è¯†ç›å€¼ç”Ÿæˆå…¬å…±çŸ©é˜µAï¼Œå¹¶è®¡ç®—éƒ¨åˆ†å…¬é’¥å’Œå…¨å±€å…¬é’¥"""
        print(f"[Participant {self.participant_id}] Generating public matrix A from consensus salt...")
        
        if self.consensus_salt is None:
            print(f"[Participant {self.participant_id}] âš ï¸  No consensus salt available!")
            return
        
        start_time = time.time()
        
        # ä½¿ç”¨å…±è¯†ç›å€¼ç”ŸæˆéšæœºçŸ©é˜µAï¼ˆç»´åº¦ä¸º dÃ—dï¼‰
        # ä½¿ç”¨SHAKE-256æ‰©å±•è¾“å‡ºå‡½æ•°ç”Ÿæˆè¶³å¤Ÿçš„éšæœºå­—èŠ‚
        matrix_size = self.d * self.d
        bytes_needed = matrix_size * 4  # æ¯ä¸ªå…ƒç´ ç”¨4å­—èŠ‚è¡¨ç¤º
        
        # ä»å…±è¯†ç›å€¼æ´¾ç”ŸçŸ©é˜µå…ƒç´ 
        random_bytes = hashlib.shake_256(self.consensus_salt.encode()).digest(bytes_needed)
        
        # æ„å»ºéšæœºçŸ©é˜µAï¼ˆå…ƒç´ èŒƒå›´ï¼š[0, 2^31-1]ï¼Œä½¿ç”¨æ¨¡è¿ç®—ç¡®ä¿åœ¨æœ‰é™åŸŸå†…ï¼‰
        A = np.zeros((self.d, self.d), dtype=object)
        
        for i in range(self.d):
            for j in range(self.d):
                byte_idx = (i * self.d + j) * 4
                # å°†4ä¸ªå­—èŠ‚è½¬æ¢ä¸ºä¸€ä¸ªæ•´æ•°
                value = int.from_bytes(random_bytes[byte_idx:byte_idx+4], byteorder='big')
                # ä½¿ç”¨æ¨¡è¿ç®—å°†å€¼é™åˆ¶åœ¨æœ‰é™åŸŸå†…
                A[i, j] = value % self.v3s.prime
        
        self.public_matrix_A = A
        
        matrix_gen_time = time.time() - start_time
        print(f"[Participant {self.participant_id}] Generated {self.d}Ã—{self.d} public matrix A ({matrix_gen_time*1000:.2f} ms)")
        print(f"[Participant {self.participant_id}] Matrix structure: A_{self.d}Ã—{self.d}")
        
        # è®¡ç®—éƒ¨åˆ†å…¬é’¥ b_i = A * s_i
        partial_key_start = time.time()
        
        if self.secret_vector is None:
            raise ValueError("Secret vector unavailable for key generation")

        secret_vector = np.array(self.secret_vector, dtype=object)
        
        partial_public_key = np.zeros(self.d, dtype=object)
        for i in range(self.d):
            value = 0
            for j in range(self.d):
                value = (value + int(self.public_matrix_A[i, j]) * int(secret_vector[j])) % self.v3s.prime
            partial_public_key[i] = int(value)
        
        self.partial_public_key = partial_public_key.tolist()
        
        partial_key_time = time.time() - partial_key_start
        print(f"[Participant {self.participant_id}] Computed partial public key b_{self.participant_id} = A * s_{self.participant_id} ({partial_key_time*1000:.2f} ms)")
        print(f"[Participant {self.participant_id}] Partial public key: {[int(val) % 1000 for val in self.partial_public_key[:min(4, len(self.partial_public_key))]]}... (mod 1000)")
        
        # å¹¿æ’­éƒ¨åˆ†å…¬é’¥
        broadcast_start = time.time()

        # åˆ›å»ºéƒ¨åˆ†å…¬é’¥æ¶ˆæ¯ï¼ˆä½¿ç”¨ç°æœ‰çš„æ¶ˆæ¯ç±»æˆ–åˆ›å»ºæ–°çš„ï¼‰
        # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ç½‘ç»œç›´æ¥å¹¿æ’­
        partial_key_message = {
            'participant_id': self.participant_id,
            'partial_public_key': self.partial_public_key
        }

        # å¹¿æ’­éƒ¨åˆ†å…¬é’¥ç»™æ‰€æœ‰å‚ä¸è€…
        with self.network.lock:
            for pid in self.network.message_queues.keys():
                self.network.message_queues[pid].put(('partial_key', partial_key_message))

        broadcast_time = time.time() - broadcast_start
        print(f"[Participant {self.participant_id}] Broadcasted partial public key ({broadcast_time*1000:.2f} ms)")
        
        # æ¥æ”¶å…¶ä»–å‚ä¸è€…çš„éƒ¨åˆ†å…¬é’¥
        time.sleep(0.5)  # ç­‰å¾…å…¶ä»–å‚ä¸è€…å¹¿æ’­
        receive_start = time.time()
        
        received_partial_keys = {}
        received_partial_keys[self.participant_id] = self.partial_public_key
        
        # è·å–æ‰€æœ‰æœ‰æ•ˆå‚ä¸è€…çš„ID
        all_valid_ids = sorted(set(self.valid_shares + [self.participant_id]))
        
        timeout = 2.0
        start_wait = time.time()
        messages_to_requeue = []
        
        while len(received_partial_keys) < len(all_valid_ids) and time.time() - start_wait < timeout:
            try:
                msg_type, data = self.network.message_queues[self.participant_id].get(timeout=0.1)
                if msg_type == 'partial_key':
                    pid = data['participant_id']
                    if pid in all_valid_ids and pid not in received_partial_keys:
                        received_partial_keys[pid] = data['partial_public_key']
                        print(f"[Participant {self.participant_id}] Received partial public key from Participant {pid}")
                else:
                    messages_to_requeue.append((msg_type, data))
            except:
                break
        
        # é‡æ–°æ”¾å›ééƒ¨åˆ†å…¬é’¥æ¶ˆæ¯
        for msg in messages_to_requeue:
            self.network.message_queues[self.participant_id].put(msg)
        
        receive_time = time.time() - receive_start
        print(f"[Participant {self.participant_id}] Received {len(received_partial_keys)-1} partial public keys ({receive_time*1000:.2f} ms)")
        
        # è®¡ç®—å…¨å±€å…¬é’¥ b = b_1 + b_2 + ... + b_n
        aggregate_start = time.time()
        
        global_public_key = np.zeros(self.d, dtype=object)
        
        for pid in sorted(received_partial_keys.keys()):
            partial_key = received_partial_keys[pid]
            for i in range(self.d):
                global_public_key[i] = (int(global_public_key[i]) + int(partial_key[i])) % self.v3s.prime
        
        self.global_public_key = global_public_key.tolist()
        
        aggregate_time = time.time() - aggregate_start
        
        total_key_time = matrix_gen_time + partial_key_time + broadcast_time + receive_time + aggregate_time
        
        # è®°å½•å¹¶æš´éœ²å…¨å±€å…¬é’¥ç”Ÿæˆçš„æ—¶é—´ä¸ç»Ÿè®¡ï¼Œä¾¿äºæœ€åç»Ÿä¸€èšåˆä¸º Phase 7
        self.public_key_generation_time = total_key_time
        try:
            self.v3s.add_performance_stat(
                "å…¨å±€å…¬é’¥ç”Ÿæˆ",
                total_key_time,
                {
                    "çŸ©é˜µç”Ÿæˆ (A, dÃ—d)": self.d * self.d,
                    "éƒ¨åˆ†å…¬é’¥è®¡ç®— (AÃ—s_i)": self.d * self.d,
                    "éƒ¨åˆ†å…¬é’¥å¹¿æ’­ (æ¯ä¸ªå‚ä¸è€…)": len(self.network.message_queues),
                    "éƒ¨åˆ†å…¬é’¥æ¥æ”¶ (ä¼°è®¡æ¯ä¸ªå‚ä¸è€…æ¥æ”¶)": len(all_valid_ids)
                }
            )
        except Exception:
            # å…¼å®¹æ€§ä¿æŠ¤ï¼šè‹¥åœ¨æŸäº›æµ‹è¯•è·¯å¾„ä¸­æ— æ³•è®°å½•ï¼Œä¸å½±å“ä¸»æµç¨‹
            pass
        
        print(f"[Participant {self.participant_id}] âœ“ Computed global public key b = sum(b_i) ({aggregate_time*1000:.2f} ms)")
        print(f"[Participant {self.participant_id}] Global public key: {[int(val) % 1000 for val in self.global_public_key[:min(4, len(self.global_public_key))]]}... (mod 1000)")
        print(f"[Participant {self.participant_id}] Total public key generation time: {total_key_time*1000:.2f} ms")

def test_distributed_v3s():
    """æµ‹è¯•åˆ†å¸ƒå¼V3Såè®®"""
    print("\n" + "="*80)
    print("***  DISTRIBUTED V3S PROTOCOL TEST  ***".center(80))
    print("="*80 + "\n")
    
    # åè®®å‚æ•°
    num_participants = 5
    threshold = 3
    dimension = 4
    sigma_x = 1.0
    sigma_y = sigma_x * (337 ** 0.5)
    
    print("*** Protocol Parameters ***")
    print(f"  â€¢ Number of participants (N): {num_participants}")
    print(f"  â€¢ Threshold (T):              {threshold}")
    print(f"  â€¢ Vector dimension (d):       {dimension}")
    print(f"  â€¢ sigma_x:                    {sigma_x:.2f}")
    print(f"  â€¢ sigma_y:                    {sigma_y:.2f} (= âˆš337 Ã— sigma_x)")
    print(f"  â€¢ Prime field size:           2^255 - 19")
    print(f"  â€¢ Prime bit length:           {PRIME.bit_length()} bits")
    print(f"  â€¢ Encryption:                 X25519 KEM + AES-256-GCM (Ed25519 signatures)")
    print("-" * 80 + "\n")
    
    # åˆ›å»ºç½‘ç»œæ¨¡æ‹Ÿå™¨
    network = NetworkSimulator()
    
    # åˆ›å»ºæ‰€æœ‰å‚ä¸è€…
    participants = []
    for i in range(1, num_participants + 1):
        network.register_participant(i)
        participant = DistributedParticipant(
            participant_id=i,
            n=num_participants,
            t=threshold,
            d=dimension,
            network=network,
            sigma_x=sigma_x,
            sigma_y=sigma_y
        )
        participants.append(participant)
    
    print("*** Starting Distributed Protocol ***\n")
    print("\n" + "="*80)
    print("***  SHARE AND VERIFY PHRASE  ***".center(80))
    print("="*80 + "\n")
    
    # å¯åŠ¨æ‰€æœ‰å‚ä¸è€…çº¿ç¨‹
    start_time = time.time()
    for participant in participants:
        participant.start()
    
    # ç­‰å¾…æ‰€æœ‰å‚ä¸è€…å®Œæˆ
    for participant in participants:
        participant.join()
    
    total_time = time.time() - start_time
    
    # ç»Ÿè®¡éªŒè¯ç»“æœå’ŒæŠ•è¯‰æƒ…å†µ
    all_verified = True
    total_verification_time = 0
    all_verification_ops = []
    total_complaints = 0
    
    print("\n")
    
    for participant in participants:
        verified_count = sum(participant.verification_results)
        expected_count = num_participants - 1
        valid_shares_count = len(participant.valid_shares)
        complaints_sent = len(participant.complaints_sent)
        complaints_received = len(participant.complaints_received)
        
        status = "âœ“ SUCCESS" if verified_count == expected_count else "âœ— PARTIAL"
        consensus_salt_preview = participant.consensus_salt[:16] + "..." if participant.consensus_salt else "None"
        print(f"  Participant {participant.participant_id}: {status} - Verified {verified_count}/{expected_count} shares | Valid: {valid_shares_count} | Complaints sent: {complaints_sent} | Complaints received: {complaints_received} | Consensus: {consensus_salt_preview}")
        
        if verified_count != expected_count:
            all_verified = False
        
        # æ”¶é›†éªŒè¯ç»Ÿè®¡
        total_verification_time += sum(participant.verification_times)
        all_verification_ops.extend(participant.verification_ops)
        total_complaints += complaints_sent
    
    print(f"\n  â±  Total execution time: {total_time*1000:.2f} ms")
    print(f"  ğŸ“Š Total messages sent: {(num_participants * (num_participants - 1)) + num_participants * num_participants + total_complaints * num_participants}")
    print(f"     - Encrypted shares:  {num_participants * (num_participants - 1)}")
    print(f"     - Public proofs:     {num_participants} (broadcasted to all)")
    print(f"     - Complaints:        {total_complaints} (broadcasted to all)")
    
    # æŠ•è¯‰ç»Ÿè®¡
    if total_complaints > 0:
        print(f"\n  âš ï¸  Complaint Summary:")
        for participant in participants:
            if participant.complaints_sent:
                for complaint in participant.complaints_sent:
                    print(f"     - P{complaint.complainer_id} complained about P{complaint.accused_id}: {complaint.reason}")
    
    # å…±è¯†ç›å€¼éªŒè¯
    print(f"\n  ğŸ” Consensus Salt Verification:")
    consensus_salts = [p.consensus_salt for p in participants if p.consensus_salt]
    if consensus_salts:
        unique_salts = set(consensus_salts)
        if len(unique_salts) == 1:
            print(f"     âœ“ All participants reached consensus!")
            print(f"     Consensus salt: {consensus_salts[0][:32]}...")
        else:
            print(f"     âœ— WARNING: Participants have different consensus salts!")
            for i, participant in enumerate(participants):
                print(f"     P{participant.participant_id}: {participant.consensus_salt[:32]}...")
    else:
        print(f"     âœ— No consensus salt computed")
    
    # åˆå¹¶æ‰€æœ‰éªŒè¯æ“ä½œç»Ÿè®¡
    if all_verification_ops:
        combined_verify_ops = {}
        for ops in all_verification_ops:
            for key, value in ops.items():
                combined_verify_ops[key] = combined_verify_ops.get(key, 0) + value
        
        avg_verify_time = total_verification_time / len(all_verification_ops) if all_verification_ops else 0
        print(f"\n  ğŸ” Average verification time: {avg_verify_time*1000:.4f} ms per share")
    
    # å…¨å±€ç§˜å¯†é‡æ„é˜¶æ®µ
    print("\n" + "="*80)
    print("***  GLOBAL SECRET RECONSTRUCTION  ***".center(80))
    print("="*80 + "\n")
    
    # éªŒè¯æ‰€æœ‰å‚ä¸è€…æ˜¯å¦æˆåŠŸé‡æ„å…¨å±€ç§˜å¯†
    global_secrets = {}
    reconstruction_times = {}
    
    for participant in participants:
        if participant.global_secret is not None:
            global_secrets[participant.participant_id] = participant.global_secret
            reconstruction_times[participant.participant_id] = participant.reconstruction_time
            print(f"  Participant {participant.participant_id}: âœ“ Reconstructed global secret")
            print(f"     Global secret: {participant.global_secret}")
            print(f"     ||S_global|| = {np.linalg.norm(participant.global_secret):.4f}")
            print(f"     Reconstruction time: {participant.reconstruction_time*1000:.2f} ms")
        else:
            print(f"  Participant {participant.participant_id}: âœ— Failed to reconstruct global secret")
    
    # éªŒè¯ä¸€è‡´æ€§ï¼šæ‰€æœ‰å‚ä¸è€…é‡æ„çš„å…¨å±€ç§˜å¯†åº”è¯¥ç›¸åŒ
    if global_secrets:
        unique_secrets = list(set([tuple(s) for s in global_secrets.values()]))
        if len(unique_secrets) == 1:
            print(f"\n  âœ“ All participants reconstructed the SAME global secret!")
            print(f"  Global secret: {list(unique_secrets[0])}")
            print(f"  ||S_global|| = {np.linalg.norm(unique_secrets[0]):.4f}")
        else:
            print(f"\n  âœ— WARNING: Participants reconstructed DIFFERENT global secrets!")
            for pid, secret in global_secrets.items():
                print(f"     P{pid}: {secret}")
        
        # éªŒè¯å…¨å±€ç§˜å¯†æ˜¯å¦ç­‰äºæ‰€æœ‰å‚ä¸è€…ç§˜å¯†çš„å’Œ
        print(f"\n  ğŸ“Š Verification: S_global = S_1 + S_2 + ... + S_n")
        
        # è®¡ç®—æœŸæœ›çš„å…¨å±€ç§˜å¯†ï¼ˆæ‰€æœ‰å‚ä¸è€…åŸå§‹ç§˜å¯†çš„å’Œï¼‰
        expected_global_secret = [0] * dimension
        for participant in participants:
            secret = participant.secret_vector
            for i in range(dimension):
                expected_global_secret[i] += secret[i]
        
        print(f"  Expected global secret (sum of all secrets): {expected_global_secret}")
        print(f"  Expected ||S_global|| = {np.linalg.norm(expected_global_secret):.4f}")
        
        # æ¯”è¾ƒé‡æ„çš„å…¨å±€ç§˜å¯†ä¸æœŸæœ›å€¼
        if unique_secrets:
            reconstructed = list(unique_secrets[0])
            match = all(abs(reconstructed[i] - expected_global_secret[i]) < 1e-6 for i in range(dimension))
            if match:
                print(f"  âœ“ Reconstructed global secret MATCHES expected sum!")
            else:
                print(f"  âœ— Reconstructed global secret DOES NOT match expected sum!")
                print(f"  Difference: {[reconstructed[i] - expected_global_secret[i] for i in range(dimension)]}")
        
        # å¹³å‡é‡æ„æ—¶é—´
        avg_recon_time = np.mean(list(reconstruction_times.values()))
        print(f"\n  â±  Average global secret reconstruction time: {avg_recon_time*1000:.2f} ms")
    else:
        print(f"\n  âœ— No participants successfully reconstructed the global secret")
    
    # å…¨å±€å…¬é’¥éªŒè¯é˜¶æ®µ
    print("\n" + "="*80)
    print("***  GLOBAL PUBLIC KEY GENERATION  ***".center(80))
    print("="*80 + "\n")
    
    # éªŒè¯æ‰€æœ‰å‚ä¸è€…æ˜¯å¦æˆåŠŸç”Ÿæˆå…¨å±€å…¬é’¥
    global_public_keys = {}
    partial_public_keys = {}
    public_matrices = {}
    
    for participant in participants:
        if participant.global_public_key is not None:
            global_public_keys[participant.participant_id] = participant.global_public_key
            partial_public_keys[participant.participant_id] = participant.partial_public_key
            public_matrices[participant.participant_id] = participant.public_matrix_A
            
            print(f"  Participant {participant.participant_id}: âœ“ Generated global public key")
            print(f"     Partial key b_{participant.participant_id}: {[int(val) % 1000 for val in participant.partial_public_key[:4]]}... (mod 1000)")
            print(f"     Global key b: {[int(val) % 1000 for val in participant.global_public_key[:4]]}... (mod 1000)")
        else:
            print(f"  Participant {participant.participant_id}: âœ— Failed to generate global public key")
    
    # éªŒè¯ä¸€è‡´æ€§
    if global_public_keys:
        # éªŒè¯æ‰€æœ‰å‚ä¸è€…çš„å…¬å…±çŸ©é˜µAç›¸åŒ
        print(f"\n  ğŸ” Public Matrix A Verification:")
        if public_matrices:
            # æ¯”è¾ƒæ‰€æœ‰çŸ©é˜µæ˜¯å¦ç›¸åŒ
            matrix_list = list(public_matrices.values())
            all_same = True
            first_matrix = matrix_list[0]
            
            for matrix in matrix_list[1:]:
                if not np.array_equal(first_matrix, matrix):
                    all_same = False
                    break
            
            if all_same:
                print(f"     âœ“ All participants generated the SAME public matrix A!")
                print(f"     Matrix A shape: {first_matrix.shape} (expected: {dimension}Ã—{dimension})")
                print(f"     Matrix A preview (first row, mod 1000): {[int(val) % 1000 for val in first_matrix[0][:min(4, dimension)]]}")
            else:
                print(f"     âœ— WARNING: Participants generated DIFFERENT public matrices!")
        
        # éªŒè¯æ‰€æœ‰å‚ä¸è€…è®¡ç®—çš„å…¨å±€å…¬é’¥ç›¸åŒ
        print(f"\n  ğŸ”‘ Global Public Key Verification:")
        unique_keys = list(set([tuple(k) for k in global_public_keys.values()]))
        
        if len(unique_keys) == 1:
            print(f"     âœ“ All participants computed the SAME global public key!")
            print(f"     Global public key b: {[int(val) % 1000 for val in unique_keys[0][:4]]}... (mod 1000)")
        else:
            print(f"     âœ— WARNING: Participants computed DIFFERENT global public keys!")
            for pid, key in global_public_keys.items():
                print(f"     P{pid}: {[int(val) % 1000 for val in key[:4]]}... (mod 1000)")
        
        # éªŒè¯æ•°å­¦æ­£ç¡®æ€§ï¼šb = A * s_global
        print(f"\n  ğŸ“Š Mathematical Verification: b = A * s_global")

        if global_secrets and public_matrices:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå‚ä¸è€…çš„çŸ©é˜µAå’Œå…¨å±€ç§˜å¯†è®¡ç®—æœŸæœ›çš„å…¨å±€å…¬é’¥
            A_matrix = list(public_matrices.values())[0]
            s_global = np.array(list(global_secrets.values())[0], dtype=object)

            expected_global_key = np.zeros(dimension, dtype=object)
            for i in range(dimension):
                value = 0
                for j in range(dimension):
                    value = (value + int(A_matrix[i, j]) * int(s_global[j])) % PRIME
                expected_global_key[i] = int(value)

            expected_global_key_list = expected_global_key.tolist()

            print(f"  Expected b = A * s_global: {[int(val) % 1000 for val in expected_global_key_list[:4]]}... (mod 1000)")

            # æ¯”è¾ƒè®¡ç®—çš„å…¨å±€å…¬é’¥ä¸æœŸæœ›å€¼
            if unique_keys:
                computed_key = list(unique_keys[0])
                match = all(int(computed_key[i]) % PRIME == int(expected_global_key_list[i]) % PRIME for i in range(dimension))

                if match:
                    print(f"  âœ“ Global public key MATCHES A * s_global!")
                else:
                    print(f"  âœ— Global public key DOES NOT match A * s_global!")
                    print(f"  Difference (first 4): {[int(computed_key[i]) - int(expected_global_key_list[i]) for i in range(min(4, dimension))]}")

        # éªŒè¯ï¼šb = sum(b_i) = sum(A * s_i)
        print(f"\n  ğŸ“Š Verification: b = sum(b_i) = sum(A * s_i)")
        
        if partial_public_keys and len(partial_public_keys) >= threshold:
            # è®¡ç®—æ‰€æœ‰éƒ¨åˆ†å…¬é’¥çš„å’Œ
            computed_sum = np.zeros(dimension, dtype=object)
            
            for pid, partial_key in partial_public_keys.items():
                for i in range(dimension):
                    computed_sum[i] = (int(computed_sum[i]) + int(partial_key[i])) % PRIME
            
            computed_sum_list = computed_sum.tolist()
            
            print(f"  Computed sum(b_i): {[int(val) % 1000 for val in computed_sum_list[:4]]}... (mod 1000)")
            
            if unique_keys:
                global_key = list(unique_keys[0])
                match = all(int(global_key[i]) % PRIME == int(computed_sum_list[i]) % PRIME for i in range(dimension))
                
                if match:
                    print(f"  âœ“ Global public key b MATCHES sum(b_i)!")
                else:
                    print(f"  âœ— Global public key b DOES NOT match sum(b_i)!")
    else:
        print(f"\n  âœ— No participants successfully generated global public key")
    
    # æ‰“å°æ€§èƒ½æŠ¥å‘Šï¼ˆèšåˆæ‰€æœ‰å‚ä¸è€…çš„æ•°æ®ï¼‰
    if participants:
        # åˆ›å»ºèšåˆçš„æ€§èƒ½ç»Ÿè®¡
        aggregated_v3s = V3S(num_participants, threshold)
        
        # ç»Ÿä¸€å®šä¹‰å¹¶æŒ‰é¡ºåºèšåˆå›ºå®šçš„ 7 ä¸ªé˜¶æ®µï¼ˆå·²ç§»é™¤å™ªå£°ç”Ÿæˆé˜¶æ®µï¼‰
        phase_names = [
            "Shamirç§˜å¯†å…±äº«",
            "Merkleæ ‘æ„å»º",
            "æŒ‘æˆ˜çŸ©é˜µä¸ç•Œé™è®¡ç®—",
            "éªŒè¯å‘é‡è®¡ç®—",
            "ç½‘ç»œé€šä¿¡",
            "å…¨å±€ç§˜å¯†é‡æ„",
            "å…¨å±€å…¬é’¥ç”Ÿæˆ"
        ]
        
        # èšåˆå‰å››ä¸ªè®¡ç®—é˜¶æ®µï¼ˆè¿™äº›é˜¶æ®µçš„ç»Ÿè®¡ä¿å­˜åœ¨æ¯ä¸ªå‚ä¸è€…çš„ v3s.performance_stats ä¸­ï¼Œä¸”é¡ºåºä¸€è‡´ï¼‰
        for phase_idx, phase_name in enumerate(phase_names[:4]):
            phase_durations = []
            combined_operations = {}
            for participant in participants:
                if phase_idx < len(participant.v3s.performance_stats):
                    stat = participant.v3s.performance_stats[phase_idx]
                    phase_durations.append(stat.duration)
                    for op_name, count in stat.operations.items():
                        combined_operations[op_name] = combined_operations.get(op_name, 0) + count
            max_duration = max(phase_durations) if phase_durations else 0
            aggregated_v3s.add_performance_stat(phase_name, max_duration, combined_operations)
        
        # ç½‘ç»œé€šä¿¡é˜¶æ®µï¼ˆå¹¶å‘ï¼Œå–æœ€å¤§å€¼ï¼‰
        network_times = [p.network_send_time + p.network_receive_time for p in participants]
        max_network_time = max(network_times) if network_times else 0
        combined_network_ops = {}
        for participant in participants:
            for op_name, count in participant.network_ops.items():
                combined_network_ops[op_name] = combined_network_ops.get(op_name, 0) + count
        aggregated_v3s.add_performance_stat("ç½‘ç»œé€šä¿¡", max_network_time, combined_network_ops)
        
        # å…¨å±€ç§˜å¯†é‡æ„ï¼ˆå¹¶å‘ï¼Œå–æœ€å¤§å€¼ï¼‰
        if reconstruction_times:
            max_global_recon_time = max(reconstruction_times.values())
        else:
            max_global_recon_time = 0
        aggregated_v3s.add_performance_stat(
            "å…¨å±€ç§˜å¯†é‡æ„",
            max_global_recon_time,
            {
                "èšåˆä»½é¢è®¡ç®— (æ¯ä¸ªå‚ä¸è€…è®¡ç®—è‡ªå·±ä½ç½®çš„èšåˆä»½é¢)": num_participants,
                "èšåˆä»½é¢å¹¿æ’­ (æ¯ä¸ªå‚ä¸è€…å¹¿æ’­è‡ªå·±çš„èšåˆä»½é¢)": num_participants,
                "èšåˆä»½é¢æ¥æ”¶ (æ¯ä¸ªå‚ä¸è€…æ¥æ”¶å…¶ä»–äººçš„èšåˆä»½é¢)": num_participants * num_participants,
                "æ‹‰æ ¼æœ—æ—¥æ’å€¼ (ä½¿ç”¨tä¸ªèšåˆä»½é¢é‡æ„å…¨å±€ç§˜å¯†)": num_participants * dimension,
                "æ¨¡é€†å…ƒè®¡ç®— (æ‹‰æ ¼æœ—æ—¥æ’å€¼ä¸­çš„æ¨¡é€†è¿ç®—)": num_participants * dimension * threshold * (threshold - 1),
                "æ¨¡ä¹˜æ³• (æ‹‰æ ¼æœ—æ—¥åŸºå‡½æ•°è®¡ç®—)": num_participants * dimension * threshold * threshold * 2,
            }
        )
        
        # å…¨å±€å…¬é’¥ç”Ÿæˆï¼ˆå¹¶å‘ï¼Œå–æœ€å¤§å€¼ï¼‰â€”â€” Phase 7
        public_key_times = [p.public_key_generation_time for p in participants]
        max_pub_key_time = max(public_key_times) if public_key_times else 0
        combined_pub_ops = {
            "çŸ©é˜µç”Ÿæˆ (A, dÃ—d, æ‰€æœ‰å‚ä¸è€…)": num_participants * dimension * dimension,
            "éƒ¨åˆ†å…¬é’¥è®¡ç®— (AÃ—s_i, æ‰€æœ‰å‚ä¸è€…)": num_participants * dimension * dimension,
            "éƒ¨åˆ†å…¬é’¥å¹¿æ’­ (ä¼°è®¡)": num_participants,
            "éƒ¨åˆ†å…¬é’¥æ¥æ”¶ (ä¼°è®¡)": num_participants * num_participants
        }
        aggregated_v3s.add_performance_stat("å…¨å±€å…¬é’¥ç”Ÿæˆ", max_pub_key_time, combined_pub_ops)
        
        aggregated_v3s.print_performance_report()

if __name__ == "__main__":
    test_distributed_v3s()
